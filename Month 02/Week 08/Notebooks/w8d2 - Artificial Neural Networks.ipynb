{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae75050c",
   "metadata": {},
   "source": [
    "# Summer of Code - Artificial Intelligence\n",
    "## Week 08: Deep Learning\n",
    "\n",
    "### Day 02: Artificial Neural Networks\n",
    "\n",
    "In this notebook, we will explore **Artificial Neural Networks (ANNs)** using PyTorch library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eff8238",
   "metadata": {},
   "source": [
    "# Deep Learning\n",
    "Deep Learning is a subset of Machine Learning that focuses on using neural networks to model and understand complex patterns in data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c074b89",
   "metadata": {},
   "source": [
    "# Artificial Neuron\n",
    "An artificial neuron is a computational model inspired by the biological neurons in the human brain. It takes multiple inputs, processes them, and produces an output based on a weighted sum and an activation function.\n",
    "\n",
    "<img src=\"neuron.png\" alt=\"Artificial Neuron\" width=\"420\"/>\n",
    "\n",
    "Mathematically, an artificial neuron can be represented as:\n",
    "$$\n",
    "\\text{output} = \\phi \\left(\\sum_{i=1}^{n} (\\text{weight}_i \\cdot \\text{input}_i) + \\text{bias}\\right)\n",
    "$$\n",
    "Where:\n",
    "- $\\text{input}_i$: The inputs to the neuron.\n",
    "- $\\text{weight}_i$: The weights associated with each input.\n",
    "- $\\text{bias}$: A bias term that helps shift the activation function.\n",
    "- $\\phi$: A non-linear function that determines the output of the neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d97debab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def step(x):\n",
    "    # if x > 0:\n",
    "    #     return 1\n",
    "    # else:\n",
    "    #     return -1\n",
    "\n",
    "    return np.where(x > 0, 1, -1)\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def relu(x):\n",
    "    # return x if x > 0 else 0\n",
    "    return np.maximum(0, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4167bbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuron(inputs, weights, bias, activation):\n",
    "    output = np.dot(inputs, weights) + bias\n",
    "    return activation(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fb2778e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.6364525402815664)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "setosa1 = [0.5, 0.3, 0.6, 0.7]\n",
    "\n",
    "weights = [0.4, 0.6, 0.2, 0.8]\n",
    "\n",
    "bias = -0.5\n",
    "\n",
    "neuron(setosa1, weights, bias, sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd8edf1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.18242552, 0.37754067, 0.37754067, 0.62245933])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([\n",
    "    [0.0, 0.0],\n",
    "    [0.0, 1.0],\n",
    "    [1.0, 0.0],\n",
    "    [1.0, 1.0]\n",
    "])\n",
    "\n",
    "y = np.array([0, 0, 0, 1])  # AND gate\n",
    "\n",
    "weights = np.array([1.0, 1.0])\n",
    "\n",
    "bias = -1.5\n",
    "\n",
    "neuron(X, weights, bias, sigmoid)  # 0 AND 0 = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4e76f8",
   "metadata": {},
   "source": [
    "# Pytorch\n",
    "It is an open-source machine learning library developed by Facebook's AI Research lab. It provides a flexible and efficient way to build and train deep learning models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be24c29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cf118adc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[ 0.0788, -0.3318],\n",
       "         [-0.4247, -0.5508],\n",
       "         [ 0.0739,  0.2762]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.5389, -0.3377, -0.6484], requires_grad=True))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron = nn.Linear(2, 3)\n",
    "perceptron.weight, perceptron.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9842f1",
   "metadata": {},
   "source": [
    "# Multilayer Perceptron (MLP)\n",
    "A Multilayer Perceptron (MLP) is a type of artificial neural network that consists of multiple layers of neurons, including an input layer, one or more hidden layers, and an output layer. Each neuron in one layer is connected to every neuron in the next layer.\n",
    "\n",
    "<img src=\"mlp.png\" alt=\"Multilayer Perceptron\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "01c38859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  2.,  3.],\n",
       "       [ 4.,  5.,  6.,  7.],\n",
       "       [ 8.,  9., 10., 11.],\n",
       "       [12., 13., 14., 15.],\n",
       "       [16., 17., 18., 19.]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.arange(20).reshape(5, 4).astype(np.float32)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "281cfbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = nn.Sequential(\n",
    "    nn.Linear(4, 3), # Layer 1\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(3, 2), # Layer 2\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(2, 3) # Layer 3, (output)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ffe21fec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Linear(in_features=4, out_features=3, bias=True),\n",
       " ReLU(),\n",
       " Linear(in_features=3, out_features=2, bias=True),\n",
       " ReLU(),\n",
       " Linear(in_features=2, out_features=3, bias=True)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(mlp.children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "69bf4354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4377,  0.3063, -0.0048],\n",
       "        [-0.4295,  0.3803, -0.0914],\n",
       "        [-0.4238,  0.4325, -0.1526],\n",
       "        [-0.4181,  0.4848, -0.2138],\n",
       "        [-0.4123,  0.5371, -0.2749]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp(torch.tensor(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b0a1fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (layer1): Linear(in_features=4, out_features=3, bias=True)\n",
       "  (layer2): Linear(in_features=3, out_features=2, bias=True)\n",
       "  (output_layer): Linear(in_features=2, out_features=3, bias=True)\n",
       "  (activation): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(4, 3)\n",
    "        self.layer2 = nn.Linear(3, 2)\n",
    "        self.output_layer = nn.Linear(2, 3)\n",
    "        self.activation = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        print(\"Forwad Pass\")\n",
    "        output = self.layer1(x)\n",
    "        output = self.activation(output)\n",
    "        output = self.layer2(output)\n",
    "        output = self.activation(output)\n",
    "        output = self.output_layer(output)\n",
    "        return output\n",
    "\n",
    "model = MLP()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9ea27c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forwad Pass\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3018, -0.0499, -0.1844],\n",
       "        [ 0.3018, -0.0499, -0.1844],\n",
       "        [ 0.3018, -0.0499, -0.1844],\n",
       "        [ 0.3018, -0.0499, -0.1844],\n",
       "        [ 0.3018, -0.0499, -0.1844]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.tensor(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bb66ec5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.0418, -0.1770, -0.2522, -0.0289],\n",
       "         [ 0.1165, -0.0187, -0.4141,  0.2237],\n",
       "         [ 0.0743,  0.0621, -0.1857,  0.0110]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.4445, -0.0212,  0.2046], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.4330,  0.4797,  0.0369],\n",
       "         [ 0.2127, -0.5427, -0.3802]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.2495, 0.4545], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.3983, -0.2311],\n",
       "         [-0.2511,  0.2184],\n",
       "         [ 0.5772,  0.2272]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.5062, -0.0865, -0.4317], requires_grad=True)]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19275ddc",
   "metadata": {},
   "source": [
    "# How do you train an MLP?\n",
    "Training an MLP involves the following steps:\n",
    "1. **Forward Pass**: Input data is passed through the network to obtain predictions.\n",
    "2. **Loss Calculation**: The difference between the predicted output and the actual target values is calculated using a loss function.\n",
    "3. **Backward Pass**: The gradients of the loss with respect to the model parameters are computed using backpropagation.\n",
    "4. **Parameter Update**: The model parameters (weights and biases) are updated using an optimization algorithm (e.g., Stochastic Gradient Descent, Adam) to minimize the loss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d58018",
   "metadata": {},
   "source": [
    "## Backpropagation\n",
    "Backpropagation is an algorithm used to train neural networks by calculating the gradients of the loss function with respect to each weight in the network.\n",
    "\n",
    "<img src=\"simplified_mlp.png\" alt=\"Backpropagation\" width=\"600\"/>\n",
    "<br />\n",
    "<img src=\"backpropagation.png\" alt=\"Backpropagation Algorithm\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1347e0",
   "metadata": {},
   "source": [
    "# Fashion MNIST Dataset\n",
    "The Fashion MNIST dataset is a collection of 70,000 grayscale images of 28x28 pixels, each representing a different clothing item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8d8a9e0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset FashionMNIST\n",
       "     Number of datapoints: 60000\n",
       "     Root location: ./data\n",
       "     Split: Train,\n",
       " Dataset FashionMNIST\n",
       "     Number of datapoints: 10000\n",
       "     Root location: ./data\n",
       "     Split: Test)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision import datasets\n",
    "\n",
    "fashion_mnist_train = datasets.FashionMNIST(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=None\n",
    ")\n",
    "fashion_mnist_test = datasets.FashionMNIST(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=None\n",
    ")\n",
    "\n",
    "fashion_mnist_train, fashion_mnist_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3a07f5c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T-shirt/top',\n",
       " 'Trouser',\n",
       " 'Pullover',\n",
       " 'Dress',\n",
       " 'Coat',\n",
       " 'Sandal',\n",
       " 'Shirt',\n",
       " 'Sneaker',\n",
       " 'Bag',\n",
       " 'Ankle boot']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = fashion_mnist_train.classes\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c0aa8120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'T-shirt/top': 0,\n",
       " 'Trouser': 1,\n",
       " 'Pullover': 2,\n",
       " 'Dress': 3,\n",
       " 'Coat': 4,\n",
       " 'Sandal': 5,\n",
       " 'Shirt': 6,\n",
       " 'Sneaker': 7,\n",
       " 'Bag': 8,\n",
       " 'Ankle boot': 9}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fashion_mnist_train.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ea41b8f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PIL.Image.Image image mode=L size=28x28>, 0)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fashion_mnist_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "89315446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(2,2))\n",
    "plt.imshow(fashion_mnist_train[1][0], cmap='gray')\n",
    "plt.title(f\"{classes[fashion_mnist_train[1][1]]}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c3ed22",
   "metadata": {},
   "source": [
    "# Training a Feedforward Neural Network on Cifar10 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f3a96985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(938, 157)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "fashion_mnist_train.transform = train_transform\n",
    "fashion_mnist_test.transform = train_transform\n",
    "\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=fashion_mnist_train,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=fashion_mnist_test,\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "\n",
    "len(train_loader), len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af797071",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.layer1 = nn.Linear(28*28, 128)\n",
    "        self.layer2 = nn.Linear(128, 64)\n",
    "        self.output_layer = nn.Linear(64, 10)\n",
    "        self.activation = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "model = FeedForwardNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9bc19cbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeedForwardNN(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (layer1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (layer2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (output_layer): Linear(in_features=64, out_features=10, bias=True)\n",
       "  (activation): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a2dc0be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 0.44620180130004883\n",
      "Epoch 2/5, Loss: 0.2224666327238083\n",
      "Epoch 3/5, Loss: 0.270537793636322\n",
      "Epoch 4/5, Loss: 0.4288010895252228\n",
      "Epoch 5/5, Loss: 0.19754762947559357\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for batch in train_loader:\n",
    "        images, labels = batch\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item()}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ul-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
