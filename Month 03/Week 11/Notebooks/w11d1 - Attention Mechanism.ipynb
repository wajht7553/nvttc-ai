{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b40606a1",
   "metadata": {},
   "source": [
    "# Summer of Code - Artificial Intelligence\n",
    "\n",
    "## Week 11: Deep Learning\n",
    "\n",
    "### Day 01: Machine Translation\n",
    "\n",
    "In this notebook, we will explore **Machine Translation** using **Attention Mechanism** in PyTorch.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b27b1ac",
   "metadata": {},
   "source": [
    "# Neural Machine Translation\n",
    "\n",
    "Neural Machine Translation (NMT) is another NLP task where we translate text from one language to another using neural networks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a53b138",
   "metadata": {},
   "source": [
    "## Encoder-Decoder Architecture\n",
    "\n",
    "The most common architecture for NMT is the Encoder-Decoder architecture. The encoder processes the input sentence and encodes it into a fixed-length context vector, which is then used by the decoder to generate the translated sentence.\n",
    "\n",
    "<img src=\"images/encoder_decoder.png\" alt=\"Encoder-Decoder Architecture\" width=\"600\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d72a1e2",
   "metadata": {},
   "source": [
    "### English to Urdu Translation Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f453e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "from urllib.request import urlopen, Request\n",
    "\n",
    "\n",
    "url = \"https://www.manythings.org/anki/urd-eng.zip\"\n",
    "req = Request(\n",
    "    url,\n",
    "    headers={\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "    },\n",
    ")\n",
    "with urlopen(req) as response:\n",
    "    with open(\"urd-eng.zip\", \"wb\") as f:\n",
    "        f.write(response.read())\n",
    "with ZipFile(\"urd-eng.zip\", \"r\") as zip_ref:\n",
    "    zip_ref.extractall(\"./eng-urd\")\n",
    "print(\"Dataset downloaded and extracted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "2d946e70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi.\\tسلام۔\\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #9020897 (nusrat)\\n',\n",
       " 'Help!\\tمدد۔\\tCC-BY 2.0 (France) Attribution: tatoeba.org #435084 (lukaszpp) & #1462368 (nabeel_tahir)\\n',\n",
       " 'Thanks.\\tشکریہ۔\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2057650 (nava) & #9020893 (nusrat)\\n',\n",
       " 'We won.\\tہم جیت گئے۔\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2107675 (CK) & #2123755 (nabeel_tahir)\\n',\n",
       " 'Beat it.\\tبھاگ جائو۔\\tCC-BY 2.0 (France) Attribution: tatoeba.org #37902 (CM) & #1610833 (nabeel_tahir)\\n']"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"./eng-urd/urd.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = f.readlines()\n",
    "\n",
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "218a8237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Hi.', 'سلام۔'], ['Help!', 'مدد۔'], ['Thanks.', 'شکریہ۔']]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_target = [line.strip().split(\"\\t\")[:2] for line in data]\n",
    "source_target[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "84edf46e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[\"I'll be sixteen on my next birthday.\",\n",
       "  'میں اپنی اگلی سالگرہ پر سولہ سال کا ہو جائو گا۔'],\n",
       " [\"You shouldn't eat here.\", 'تمہیں یہاں نہیں کھانا چاہئیے۔'],\n",
       " ['They became citizens of Japan.', 'انہوں نے جاپانی شہریت حاصل کرلی۔']]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "np.random.shuffle(source_target)\n",
    "source_target[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "96d82fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'll be sixteen on my next birthday. => میں اپنی اگلی سالگرہ پر سولہ سال کا ہو جائو گا۔\n",
      "You shouldn't eat here. => تمہیں یہاں نہیں کھانا چاہئیے۔\n",
      "They became citizens of Japan. => انہوں نے جاپانی شہریت حاصل کرلی۔\n"
     ]
    }
   ],
   "source": [
    "source_sentences, target_sentences = zip(*source_target)\n",
    "for i in range(3):\n",
    "    print(f\"{source_sentences[i]} => {target_sentences[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82a23a0",
   "metadata": {},
   "source": [
    "### Build Vocabulary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "9ba2a003",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sentences):\n",
    "    return [s.lower().split() for s in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "e8ea2707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[\"i'll\", 'be', 'sixteen', 'on', 'my', 'next', 'birthday.'],\n",
       "  ['you', \"shouldn't\", 'eat', 'here.'],\n",
       "  ['they', 'became', 'citizens', 'of', 'japan.']],\n",
       " [['میں',\n",
       "   'اپنی',\n",
       "   'اگلی',\n",
       "   'سالگرہ',\n",
       "   'پر',\n",
       "   'سولہ',\n",
       "   'سال',\n",
       "   'کا',\n",
       "   'ہو',\n",
       "   'جائو',\n",
       "   'گا۔'],\n",
       "  ['تمہیں', 'یہاں', 'نہیں', 'کھانا', 'چاہئیے۔'],\n",
       "  ['انہوں', 'نے', 'جاپانی', 'شہریت', 'حاصل', 'کرلی۔']])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_tokens = tokenize(source_sentences)\n",
    "target_tokens = tokenize(target_sentences)\n",
    "\n",
    "source_tokens[:3], target_tokens[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "bd8b2444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Vocabulary Size: 1500\n",
      "Urdu Vocabulary Size: 1500\n",
      "Most common English words: [('i', 284), ('the', 265), ('to', 223), ('you', 195), ('a', 167)]\n",
      "Most common Urdu words: [('میں', 376), ('ہے۔', 324), ('نے', 182), ('اس', 155), ('وہ', 149)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "def build_vocabulary(tokenized_sentences, source=True, max_vocab_size=1000):\n",
    "    word_counts = Counter()\n",
    "    for s in tokenized_sentences:\n",
    "        word_counts.update(s)\n",
    "\n",
    "    # Create vocabulary with special tokens\n",
    "    if source:\n",
    "        vocab = {\"<PAD>\": 0, \"<UNK>\": 1}\n",
    "        most_common = word_counts.most_common(max_vocab_size - 2)\n",
    "    else:\n",
    "        vocab = {\"<PAD>\": 0, \"<UNK>\": 1, \"<SOS>\": 2, \"<EOS>\": 3}\n",
    "        most_common = word_counts.most_common(max_vocab_size - 4)\n",
    "    # Add most common words\n",
    "    for word, _ in most_common:\n",
    "        vocab[word] = len(vocab)\n",
    "\n",
    "    return vocab, word_counts\n",
    "\n",
    "\n",
    "source_vocab, source_word_counts = build_vocabulary(source_tokens, max_vocab_size=1500)\n",
    "target_vocab, target_word_counts = build_vocabulary(\n",
    "    target_tokens, source=False, max_vocab_size=1500\n",
    ")\n",
    "print(\"English Vocabulary Size:\", len(source_vocab))\n",
    "print(\"Urdu Vocabulary Size:\", len(target_vocab))\n",
    "print(\"Most common English words:\", source_word_counts.most_common(5))\n",
    "print(\"Most common Urdu words:\", target_word_counts.most_common(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "cbe152e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<PAD>': 0, '<UNK>': 1, '<SOS>': 2, '<EOS>': 3, 'میں': 4, 'ہے۔': 5, 'نے': 6, 'اس': 7, 'وہ': 8, 'کے': 9, 'کو': 10, 'نہیں': 11, 'کی': 12, 'سے': 13, 'ٹام': 14, 'مجھے': 15, 'تم': 16, 'کیا': 17, 'کہ': 18, 'ہوں۔': 19, 'کا': 20, 'ہو': 21, 'ہے': 22, 'یہ': 23, 'آپ': 24, 'ایک': 25, 'کر': 26, 'ہے؟': 27, 'تھا۔': 28, 'میرے': 29, 'اپنی': 30, 'ہیں۔': 31, 'بہت': 32, 'اور': 33, 'رہا': 34, 'گا۔': 35, 'کافی': 36, 'پہ': 37, 'میری': 38, 'کچھ': 39, 'بھی': 40, 'اسے': 41, 'ہم': 42, 'گھر': 43, 'ہو؟': 44, 'گیا': 45, 'مریم': 46, 'تمہیں': 47, 'نہ': 48, 'زیادہ': 49, 'ہوا': 50, 'تھی۔': 51, 'ہو۔': 52, 'ہی': 53, 'کرنا': 54, 'سکتے': 55, 'رہے': 56, 'رہی': 57, 'کرنے': 58, 'اپنے': 59, 'میرا': 60, 'سال': 61, 'وقت': 62, 'گیا۔': 63, 'پاس': 64, 'گی۔': 65, 'پسند': 66, 'تک': 67, 'جا': 68, 'تھا': 69, 'کوئی': 70, 'لئیے': 71, 'ابھی': 72, 'آج': 73, 'تو': 74, 'کبھی': 75, 'پر': 76, 'یہاں': 77, 'ساتھ': 78, 'تمھیں': 79, 'آ': 80, 'جلدی': 81, '۔': 82, 'کسی': 83, 'سب': 84, 'گئے': 85, 'گاڑی': 86, 'جائو': 87, 'جب': 88, 'ٹھیک': 89, 'کرتا': 90, 'گے۔': 91, 'کام': 92, 'ان': 93, 'اب': 94, 'بعد': 95, 'لگ': 96, 'کیا۔': 97, 'سکتا': 98, 'پتہ': 99, 'خیال': 100, 'انہوں': 101, 'کل': 102, 'کوشش': 103, 'کتاب': 104, 'ہوں': 105, 'ہمیں': 106, 'ضرورت': 107, 'بڑی': 108, 'پہلی': 109, 'ہر': 110, 'کی۔': 111, 'پہلے': 112, 'رات': 113, 'دے': 114, 'واپس': 115, 'تھے۔': 116, 'چاہتا': 117, 'برائے': 118, 'ابو': 119, 'انگریزی': 120, 'دفعہ': 121, 'کس': 122, 'جو': 123, 'پیسے': 124, 'ہوئے': 125, 'دیا۔': 126, 'مدد': 127, 'طرح': 128, 'ڈاکٹر': 129, 'زندگی': 130, 'کرو۔': 131, 'اپنا': 132, 'بھائی': 133, 'بارش': 134, 'گئی': 135, 'تھوڑا': 136, 'جانتا': 137, 'دس': 138, 'بہن': 139, 'صبح': 140, 'کم': 141, 'لے': 142, 'ہفتے': 143, 'لیا۔': 144, 'جواب': 145, 'کھانے': 146, 'باہر': 147, 'کیسے': 148, 'بس': 149, 'دن': 150, 'غلط': 151, 'دیر': 152, 'دو': 153, 'آئے': 154, 'مگر': 155, 'تین': 156, 'گھڑی': 157, 'ہمیشہ': 158, 'مہربانی': 159, 'انتظار': 160, 'بتایا': 161, 'شروع': 162, 'جانا': 163, 'گے؟': 164, 'لغت': 165, 'لئے': 166, 'بجے': 167, 'ٹی': 168, 'نہیں۔': 169, 'بڑا': 170, 'بند': 171, 'لوگ': 172, 'پانچ': 173, 'ہاتھ': 174, 'کرے': 175, 'دی': 176, 'چاہئیے۔': 177, 'نظر': 178, 'لگا': 179, 'موسم': 180, 'فرانسیسی': 181, 'بتا': 182, 'جیت': 183, 'ادھار': 184, 'پچھلے': 185, '؟': 186, 'کتابیں': 187, 'سارے': 188, 'صرف': 189, 'اتنی': 190, 'جانے': 191, 'زبان': 192, 'تھے': 193, 'تمھارے': 194, 'ہے،': 195, 'بیمار': 196, 'جائے': 197, 'بال': 198, 'خوبصورت': 199, 'تیراکی': 200, 'اگر': 201, 'بات': 202, 'وہاں': 203, 'کرتے': 204, 'دیا': 205, 'بچے': 206, 'کھانا': 207, 'سکتا۔': 208, 'اچھا': 209, 'دوست': 210, 'جاپان': 211, 'چلا': 212, 'والے': 213, 'امید': 214, 'مصروف': 215, 'سونے': 216, 'تھکا': 217, 'کتنی': 218, 'دو۔': 219, 'ہوٹل': 220, 'ہونے': 221, 'والد': 222, 'ختم': 223, 'پتا': 224, 'بارے': 225, 'فون': 226, 'کرو': 227, 'پہنچ': 228, 'خود': 229, 'اسی': 230, 'لیا': 231, 'کہانی': 232, 'طرف': 233, 'نیا': 234, 'مشکل': 235, 'پوری': 236, 'عمر': 237, 'لگتا': 238, 'گے': 239, 'امیر': 240, 'دور': 241, 'تیز': 242, 'لوگوں': 243, 'یاد': 244, 'اچھے': 245, 'خاندان': 246, 'آئے۔': 247, 'کب': 248, 'جاتی': 249, 'کیا؟': 250, 'کروں؟': 251, 'گرم': 252, 'صحیح': 253, 'کاش': 254, 'اتنے': 255, 'ہیں': 256, 'لڑکی': 257, 'ہوئی': 258, 'رہتا': 259, 'آیا': 260, 'استعمال': 261, 'چاہیے؟': 262, 'دوپہر': 263, 'آیا۔': 264, 'مجھ': 265, 'سکتی': 266, 'لو۔': 267, 'یا': 268, 'دی۔': 269, 'رہا۔': 270, 'رہ': 271, 'کال': 272, 'کرنا۔': 273, 'چیز': 274, 'فرق': 275, 'چھوڑ': 276, 'تمہارے': 277, 'زندہ': 278, 'دیکھا۔': 279, 'مادری': 280, 'نئی': 281, 'غلطی': 282, 'ریل': 283, 'پورے': 284, 'پڑھنے': 285, 'عورت': 286, 'دیکھا': 287, 'دوبارہ': 288, 'شاید': 289, 'ہفتہ': 290, 'والدہ': 291, 'ماں': 292, 'سکتے۔': 293, 'کہاں': 294, 'ہوتا': 295, 'کمرے': 296, 'تمہاری': 297, 'سالگرہ': 298, 'سولہ': 299, 'حاصل': 300, 'ہماری': 301, 'ملک': 302, 'جتنا': 303, 'کھا': 304, 'چاہتے': 305, 'ویل': 306, 'چیئر': 307, 'دیکھی': 308, 'تمہارا': 309, 'کیسا': 310, 'تھا؟': 311, 'آئی': 312, 'تب': 313, 'گا؟': 314, 'جس': 315, 'لی': 316, 'تھی': 317, 'دل': 318, 'چاہتا۔': 319, 'پکڑ': 320, 'کیونکہ': 321, 'ملے': 322, 'کرے۔': 323, 'خط': 324, 'سڑک': 325, 'نفرت': 326, 'چل': 327, 'بستر': 328, 'لیٹ': 329, 'بلا': 330, 'کہنا': 331, 'سکول': 332, 'میکسیکو': 333, 'اکیلے': 334, 'فوت': 335, 'ممکن': 336, 'چاہو': 337, 'لیئے': 338, 'پیار': 339, 'بیٹی': 340, 'چائے': 341, 'پھر': 342, 'گا': 343, 'ہونا': 344, 'آگے': 345, 'عجیب': 346, 'تفصیل': 347, 'مت': 348, 'کرنی': 349, 'مر': 350, 'ہوتی۔': 351, 'مرمت': 352, 'اندر': 353, 'آرام': 354, 'پانی': 355, '۱۰۰': 356, 'دیکھو۔': 357, 'رہتے': 358, 'گم': 359, 'گھنٹے': 360, 'آتے': 361, 'گئی۔': 362, 'کتنا': 363, 'پڑے': 364, 'کیسی': 365, 'چکی': 366, 'رہو۔': 367, 'اوپر': 368, 'اگلے': 369, 'دنیا': 370, 'ڈالر': 371, 'کھیل': 372, 'لی۔': 373, 'جائے۔': 374, 'رکھ': 375, 'زمین': 376, 'چائیے۔': 377, 'گرین': 378, 'پی': 379, 'بچوں': 380, 'کیوں': 381, 'زور': 382, 'پکانے': 383, 'نمبر': 384, 'کھڑکی': 385, 'ہیں؟': 386, 'فیصلہ': 387, 'صفائی': 388, 'گر': 389, 'خوش': 390, 'اگلی': 391, 'جاپانی': 392, 'پڑھنا': 393, 'عام': 394, 'ہونا۔': 395, 'آتی': 396, 'لے۔': 397, 'مرضی': 398, 'نانا': 399, 'ٹینس': 400, 'سیاہ': 401, 'ترجیح': 402, 'دوں': 403, 'تصویریں': 404, 'پیانو': 405, 'اٹھا': 406, 'سو': 407, 'زخمی': 408, 'ہار': 409, 'پورا': 410, 'تیرنا': 411, 'خریدنے': 412, 'عرصہ': 413, 'دکھ': 414, 'ادا': 415, 'چوری': 416, 'بزرگ': 417, 'اُس': 418, 'جائو۔': 419, 'جھوٹ': 420, 'نکل': 421, 'گئے۔': 422, 'دیتا': 423, 'ٹھنڈ': 424, 'بچا': 425, 'اچھی': 426, 'قیام': 427, 'چکا': 428, 'جاتے': 429, 'عموماً': 430, 'وی': 431, 'شام': 432, 'قریب': 433, 'فورا': 434, 'چھٹی': 435, '۱۹۸۳': 436, 'مہینے': 437, 'امریکا': 438, 'تھے؟': 439, 'آسان': 440, 'راز': 441, 'بڑے': 442, 'پھل': 443, 'چاہتی': 444, 'آٹھ': 445, 'پڑھتا': 446, 'چاہئیے': 447, 'کھلا': 448, 'دادا': 449, 'فلم': 450, 'بغیر': 451, 'بیس': 452, 'تصویر': 453, 'اونچا': 454, 'ایماندار': 455, 'امی': 456, 'بتائی': 457, 'ذائقہ': 458, 'روشنی': 459, 'عادت': 460, 'جان': 461, 'دونوں': 462, 'روزانہ': 463, 'ڈھیڑ': 464, 'ساری': 465, 'بھروسہ': 466, 'ہمارے': 467, 'استاد': 468, 'اتنا': 469, 'معافی': 470, 'آتا۔': 471, 'پیچھے': 472, 'عمارت': 473, 'الفاظوں': 474, 'دوسروں': 475, 'سارا': 476, 'جاتی۔': 477, 'ہفتوں': 478, 'پڑا': 479, 'گنا': 480, 'کماتا': 481, 'شوق': 482, 'پینٹ': 483, 'پوچھ': 484, 'چار': 485, 'تھوڑی': 486, 'انعام': 487, 'کون': 488, 'سا': 489, 'دیکھ': 490, 'رنگ': 491, 'فٹ': 492, 'قصور': 493, 'چھہ': 494, 'دعوت': 495, 'والا': 496, 'کتنے': 497, 'حادثہ': 498, 'ٹرین': 499, 'ڈر': 500, 'سامنے': 501, 'قسم': 502, 'باتیں': 503, 'چلو': 504, 'بلکل': 505, 'حقیقت': 506, 'یورپ': 507, 'ہوں؟': 508, 'سمجھنا': 509, 'دریا': 510, 'تمباکونوشی': 511, 'تر': 512, 'آنکھیں': 513, 'دھیان': 514, 'رکھنا': 515, 'ہوگا۔': 516, 'اجنبی': 517, 'کدھر': 518, 'وجہ': 519, 'لا': 520, 'لیے': 521, 'امتحان': 522, 'سکتی۔': 523, 'پھول': 524, 'لگی': 525, 'چہل': 526, 'قدمی': 527, 'معذرت': 528, 'طور': 529, 'کرتے۔': 530, 'بیواقوف': 531, 'رہی۔': 532, 'ابتدا': 533, 'رہتی': 534, 'بتائو۔': 535, 'فرما': 536, 'وزن': 537, 'تمھاری': 538, 'سکارف': 539, 'بچپن': 540, 'بولتا': 541, 'یقین': 542, 'جائوں': 543, 'دورہ': 544, 'ملتوی': 545, 'امریکہ': 546, 'کیمرہ': 547, 'قسمت': 548, 'قبول': 549, 'پڑی۔': 550, 'حادثے': 551, 'پڑی': 552, 'ناراض': 553, 'خطرے': 554, 'مبتلا': 555, 'بیوی': 556, 'اپ': 557, 'چیزیں': 558, 'اجلاس': 559, 'ہاتھوں': 560, 'تھا.': 561, 'آئو': 562, 'شکریہ': 563, 'پلیٹیں': 564, 'پاڑ': 565, 'جاتا': 566, 'ڈھائی': 567, 'عشائیہ': 568, 'گفتگو': 569, 'سنیما': 570, 'چیخ': 571, 'ماری': 572, 'لڑکے': 573, 'جانتے': 574, 'حال': 575, 'دیکھتے': 576, 'دودھ': 577, 'خرید': 578, 'پہنچی۔': 579, 'والی': 580, 'چاہیئے؟': 581, 'گیت': 582, 'سنا': 583, 'راستے': 584, 'کریں': 585, 'ماموں': 586, 'پیٹھ': 587, 'مقدپے': 588, 'خوشبو': 589, 'پرانے': 590, 'ٹیلی': 591, 'کالیں': 592, 'جہاں': 593, 'پلین': 594, 'معلوم': 595, 'چلے': 596, 'پیشکش': 597, 'ٹھکرا': 598, 'سن': 599, 'سبزیاں': 600, 'بھیجی۔': 601, 'جاننا': 602, 'کالج': 603, 'درخواست': 604, 'جمع': 605, 'پارٹی': 606, 'شامل': 607, 'ضروری': 608, 'ملاقات': 609, 'کہا': 610, 'جلد': 611, 'بینک': 612, 'ہوتے': 613, 'ہنسے': 614, 'دینے': 615, 'شکریہ۔': 616, 'کتا': 617, 'رکھتا': 618, 'اصل': 619, 'واقعے': 620, 'بولو۔': 621, 'بولنے': 622, 'چاول': 623, 'یار': 624, 'انہیوں': 625, 'قیمتی': 626, 'وسائل': 627, 'دوں؟': 628, 'چاچا': 629, 'بہترین': 630, 'چھوٹی': 631, 'بائسیکل': 632, 'بلیاں': 633, 'فرانس': 634, 'کمرہ': 635, 'صاف': 636, 'سنائی۔': 637, 'دکھائیں۔': 638, 'لئیے۔': 639, 'منہ': 640, 'بول': 641, 'چھٹیوں': 642, 'آسمان': 643, 'بادل': 644, 'کہنے': 645, 'پڑھتے': 646, 'حل': 647, 'جنگی': 648, 'تجربے': 649, 'بتایا۔': 650, 'برف': 651, 'پگھل': 652, 'منٹ': 653, 'ٹوپی': 654, 'سکے': 655, 'پڑتا': 656, 'ٹکٹ': 657, 'چاھتا': 658, 'ڈھونڈا': 659, 'کیسے؟': 660, 'بچہ': 661, 'فارغ': 662, 'فطرت': 663, 'برائی': 664, 'سامان': 665, 'بہار': 666, 'رک': 667, 'نا۔': 668, 'لپیٹ': 669, 'رکھو': 670, 'پرانی': 671, 'رہے۔': 672, 'چھت': 673, 'نیلی': 674, 'باقی': 675, 'لال': 676, 'ہوں،': 677, 'اٹھتے،': 678, 'نا؟': 679, 'نام': 680, 'سلام۔': 681, 'حیرت': 682, 'سفید': 683, 'چھوٹا': 684, 'ملا': 685, 'شخص': 686, 'گوشت': 687, 'ہیٹر': 688, 'لمبی': 689, 'کیک': 690, 'قیمتیں': 691, 'بڑھ': 692, 'جوان': 693, 'رائے': 694, 'اظہار': 695, 'افریقہ': 696, 'کہیں': 697, 'خراب': 698, 'بے': 699, 'مزیدار': 700, 'یے۔': 701, 'ادھر': 702, 'مل': 703, 'مریم۔': 704, 'مرد': 705, 'اسکول': 706, 'غیر': 707, 'دوسرے': 708, 'دینی': 709, 'فوج': 710, 'بیٹھ': 711, 'انکار': 712, 'محنت': 713, 'مرے': 714, 'سٹوڈنٹ': 715, 'بوس': 716, 'لغات': 717, 'بنانی': 718, 'سزائے': 719, 'موت': 720, 'اتفاق': 721, 'لگتا۔': 722, 'تمھارا': 723, 'خواب': 724, 'لگتے': 725, 'سمجھ': 726, 'سنتا': 727, 'امتہان': 728, 'بٹایا۔': 729, 'شادی': 730, 'ریستوران': 731, 'سفر': 732, 'بولے۔': 733, 'قرض': 734, 'تاکہ': 735, 'سکوں۔': 736, 'مزہ': 737, 'آرہا': 738, 'نظریہ': 739, 'دیادہ': 740, 'بور': 741, 'دلچسپ': 742, 'صفحہ': 743, 'پیش': 744, 'کرتی': 745, 'دروازہ': 746, 'ہوئی۔': 747, 'بتادو': 748, 'معاملے': 749, 'گزرے': 750, 'ریادہ': 751, 'مشورہ': 752, 'بندہ': 753, 'آگ': 754, 'بتانا': 755, 'مختلف': 756, 'خیالات': 757, 'پڑھو۔': 758, 'صحت': 759, 'کرسی': 760, 'تقریباّ': 761, 'پیتا': 762, 'چاکلیٹ': 763, 'ڈبہ': 764, 'بچانے': 765, 'طلاق': 766, 'آتی۔': 767, 'نئے': 768, 'الماری': 769, 'آجاؤنگا': 770, 'ہسپانوی': 771, 'ہوگا،': 772, 'بٹوہ': 773, 'کا؟': 774, 'خالی': 775, 'آدمی': 776, 'کالا': 777, 'بیگ': 778, 'پیس': 779, 'کیئے': 780, 'درد': 781, 'دے۔': 782, 'اٹھ': 783, '۹۰': 784, 'سائز': 785, 'انڈے': 786, 'نیچے': 787, 'گرا': 788, 'آخری': 789, 'داخل': 790, '(': 791, ')': 792, 'خامیاں': 793, 'طالب': 794, 'گرمی': 795, 'کھول': 796, 'زیارہ': 797, 'ڈھونڈو۔': 798, 'برے': 799, 'سردی': 800, 'بخیر۔': 801, 'مہنگا': 802, 'پیسوں': 803, 'خریدے؟': 804, 'عادی': 805, 'ملنے': 806, 'بیتاب': 807, 'بتائیں': 808, 'مہربانی،': 809, 'پوچھا': 810, 'شکل': 811, 'دیکھنا': 812, 'میز': 813, 'آئڈیا': 814, 'سہارا': 815, 'کھڑا': 816, 'جیسے': 817, 'جامعہ': 818, 'چلنا': 819, 'پکڑو۔': 820, 'کپ': 821, 'پڑھتی': 822, 'دفتر': 823, 'پہنج': 824, 'تلاش': 825, 'جدھر': 826, 'اڑ': 827, 'نوکری': 828, 'تایا': 829, 'زنگی': 830, 'شہریت': 831, 'کرلی۔': 832, 'واپسی': 833, 'فرمائیے۔': 834, 'بھیڑیے': 835, 'حملہ': 836, 'گانے': 837, 'دھن': 838, 'تعلق': 839, 'رکھتی': 840, 'آنکھوں': 841, 'آنسو': 842, 'موٹے': 843, 'استانی': 844, 'پہنچے': 845, 'لے،': 846, 'بڑھتا': 847, 'بینچ': 848, 'لیٹا': 849, 'ایلبم': 850, 'دکھائی۔': 851, 'میچ': 852, 'کھلاڑی': 853, 'بھرپور': 854, 'سکاٹ': 855, 'لینڈ': 856, 'جاتا۔': 857, 'بوسٹن': 858, 'ہوتا۔': 859, 'کھائیں': 860, 'پیغام': 861, 'پہنچانا': 862, 'عزت': 863, 'تحفے': 864, 'ہوئے۔': 865, 'کھینچی': 866, 'بجا': 867, 'درکار': 868, 'کئی': 869, 'لوٹائی۔': 870, 'پیو': 871, 'زیادہ۔': 872, 'الٹا': 873, 'ماضی': 874, 'کریدنا': 875, 'لینا': 876, 'اصولوں': 877, 'خلاف': 878, 'سکھایا۔': 879, 'روز': 880, 'بازار': 881, 'منعقد': 882, 'بخار': 883, 'پولیس': 884, 'رنگے': 885, 'بناتے': 886, '۱۰۰۰۰': 887, 'ین': 888, 'غربت': 889, 'مجبور': 890, 'محبت': 891, 'سے۔': 892, 'بھاگ': 893, 'بتاہا': 894, 'ہل': 895, 'پہنچنا': 896, 'دیئے۔': 897, 'بٹن': 898, 'دبانا': 899, 'کيسا': 900, 'سودا': 901, 'گالیاں': 902, 'برداشت': 903, 'ڈوبنے': 904, 'طب': 905, 'میدان': 906, 'ترقی': 907, 'شاندار': 908, 'کیلئے': 909, 'چھٹیاں': 910, 'منانے؟': 911, 'جیتے': 912, 'بدل': 913, 'پڑھو': 914, 'ہسپتال': 915, 'تعمیر': 916, 'گایا': 917, 'ہوائی': 918, 'اڈے': 919, 'بھیجو۔': 920, 'طلبہ': 921, 'سنگاپور': 922, 'چند': 923, 'اندازہ': 924, 'گولی': 925, 'نکالنے': 926, 'بتاتا': 927, '،': 928, 'غمگین': 929, 'لمحے': 930, 'گلابوں': 931, 'کیوٹو': 932, 'مندر': 933, 'دانتوں': 934, 'ایکس': 935, '-رے': 936, 'لوں': 937, 'محفوظ': 938, 'پڑھائی': 939, 'سوال': 940, 'پاگل': 941, 'مشکور': 942, 'کا،': 943, 'غور': 944, 'مسلئے': 945, 'سدِ': 946, 'باب': 947, 'لگے': 948, 'کافی۔': 949, 'دہندگان': 950, 'گزارش': 951, 'آکے': 952, 'کرائے۔': 953, 'گوند': 954, 'پلاسٹک': 955, 'جورتی۔': 956, 'بدقسمتی': 957, 'موقعہ': 958, 'گنوا': 959, 'وکیل': 960, 'گی؟': 961, 'دیکھنے': 962, 'گلاب': 963, 'پتے': 964, 'نازک': 965, 'گیم': 966, 'دیکھی۔': 967, 'تحفہ': 968, 'عجائب': 969, 'ڈیزائن': 970, 'یونیورسٹی': 971, 'ٹیچر': 972, 'حالیہ': 973, 'سمجھاتی': 974, 'بتاتی': 975, 'محافظ': 976, 'مطمئن': 977, 'برآمدگی': 978, 'اسے۔': 979, 'لنگوٹیا': 980, 'جانور': 981, 'بھوک': 982, 'واقعی': 983, 'ضائیع': 984, 'اتوار': 985, 'کھیلو': 986, 'بالکل': 987, 'پڑوڈکٹ': 988, 'بوریت': 989, 'شکار': 990, 'امنے': 991, 'ہمسایوں': 992, 'سلوک': 993, 'پتلون': 994, 'آنے': 995, 'بار': 996, 'گندی': 997, 'اپنالی،': 998, 'چھٹے': 999, 'گزرا': 1000, 'آج۔': 1001, 'موجود': 1002, 'بیلجیم': 1003, 'برا': 1004, 'تیزی': 1005, 'دھڑکنے': 1006, 'لگا۔': 1007, 'ڈرا': 1008, 'شراب': 1009, 'نوشی': 1010, 'مشکلیں': 1011, 'کی۔/اپنے': 1012, 'غم': 1013, 'کھاتے': 1014, 'رہنے': 1015, 'بولا۔': 1016, 'بھاگتے': 1017, 'چور': 1018, 'لنگوٹی': 1019, 'سہی۔': 1020, 'سورج': 1021, 'حرارت': 1022, 'ملتی': 1023, 'معلم': 1024, 'ڈگری': 1025, 'سینٹی': 1026, 'گریڈ': 1027, 'ابلتا': 1028, 'وہیں': 1029, 'تجربہ': 1030, 'ہوِئے': 1031, 'رکھا۔': 1032, 'جمیکا': 1033, 'بنایا': 1034, 'تنقید': 1035, 'سمحھ': 1036, 'جلتی': 1037, 'تھپکی': 1038, 'ٹیکسی': 1039, 'خوبصورتی': 1040, 'بیان': 1041, 'لینا۔': 1042, 'کسان': 1043, 'بننا': 1044, 'ریا': 1045, 'جرمن': 1046, 'لہجہ': 1047, 'گُم': 1048, 'سچائی': 1049, 'نک': 1050, 'ہوم': 1051, 'ورک': 1052, 'گی': 1053, 'علاوہ': 1054, 'مشہور': 1055, 'مصنف': 1056, 'بچھتائے': 1057, 'ہوت': 1058, 'چڑیا': 1059, 'چگ': 1060, 'کھیت۔': 1061, 'مایوس': 1062, 'ملو،': 1063, 'مد': 1064, 'کھڑے': 1065, 'خبر': 1066, 'سکھ': 1067, 'سانس': 1068, 'حالانکہ': 1069, 'ذخمی': 1070, 'لڑتے': 1071, 'کائنات': 1072, 'طافان': 1073, 'پابندی': 1074, 'پھنس': 1075, 'بھیگ': 1076, 'زندگیاں': 1077, 'بجلی': 1078, 'ہونگی؟': 1079, 'کنستر': 1080, 'مدد۔': 1081, 'دیں۔': 1082, 'قیامت': 1083, 'دیکھتا': 1084, 'تمہارا۔': 1085, 'مخلص': 1086, 'سیٹ': 1087, 'دیے': 1088, 'گلی': 1089, 'قلعہ': 1090, 'پوچھو': 1091, 'شطرنج': 1092, 'لندن': 1093, 'خربوزہ': 1094, 'خربوزے': 1095, 'پکڑتا': 1096, 'اہم': 1097, 'جئے': 1098, 'فرج': 1099, 'تازہ': 1100, 'کھیلتی': 1101, 'نکلا۔': 1102, 'سوچ': 1103, 'ڈوبا': 1104, 'گزاری۔': 1105, 'چاہیئے': 1106, 'ورژن': 1107, 'کتراتا': 1108, 'ہاتھی': 1109, 'ایشیا': 1110, 'پائے': 1111, 'کتے': 1112, 'رکھتے۔': 1113, 'سیدھا': 1114, 'دماغ': 1115, 'آئو؟': 1116, 'مقابلے': 1117, 'کپاس': 1118, 'مثال': 1119, 'پڑھای': 1120, 'ڈبر': 1121, 'روٹی': 1122, 'تیس': 1123, 'ہزار': 1124, 'کمائے۔': 1125, 'قطع': 1126, 'قلامی': 1127, 'معاف۔': 1128, 'حوصلہ': 1129, 'کھونا۔': 1130, 'کمیٹی': 1131, 'سات': 1132, 'عورتیں': 1133, 'دھویا': 1134, 'جانوروں': 1135, 'ڈالے۔': 1136, 'ہاروں': 1137, 'حاصر': 1138, '.': 1139, 'پہاڑوں': 1140, 'رقص': 1141, 'پتلے': 1142, 'زیادو': 1143, 'حاضری': 1144, 'ٹیکسنس': 1145, 'منظم': 1146, 'نظریں': 1147, 'جھکا': 1148, 'ہوا؟': 1149, 'دکھائو۔': 1150, 'برفباری': 1151, 'خالو': 1152, 'بوجھ': 1153, 'منگنی': 1154, 'ہوگئی': 1155, 'کمپیوٹر': 1156, 'معلومات': 1157, 'اندراج': 1158, 'پرسو': 1159, 'سانپ': 1160, 'چھٹ': 1161, 'سکی۔': 1162, '!چلو': 1163, 'آرامدہ': 1164, 'گزار': 1165, 'نوکرانی': 1166, 'ویکیوم': 1167, 'کلینر': 1168, 'گندا': 1169, 'ائیرپورٹ': 1170, 'کزن': 1171, 'چھوڑنے۔': 1172, 'بسوں': 1173, 'پیلا': 1174, 'پین': 1175, 'کبھار': 1176, 'کھو': 1177, 'غبارے': 1178, 'پوا': 1179, 'بھری': 1180, 'مہینوں': 1181, 'سکو': 1182, 'ہارڈ': 1183, 'ڈرائیو': 1184, 'تقریبا': 1185, 'بھڑھ': 1186, 'سر': 1187, 'پھٹ': 1188, 'اکیلا': 1189, 'دائیں': 1190, 'آستین': 1191, 'چڑھائو۔': 1192, 'کھائو۔': 1193, 'دھوئے۔': 1194, 'طوفان': 1195, 'نتیجے': 1196, 'ہلاک': 1197, 'رونے': 1198, 'بیٹھا': 1199, 'ہوا۔': 1200, 'بہرے': 1201, 'اکثر': 1202, 'نشانی': 1203, 'کھڑی': 1204, 'کرتا۔': 1205, 'قتل': 1206, 'کھیلتا': 1207, 'سوپر': 1208, 'مارکیٹ': 1209, 'بخير۔': 1210, 'تھی؟': 1211, 'ازماتے': 1212, 'جائیں': 1213, 'میٹنگ': 1214, 'ناچے': 1215, 'ریڈیو': 1216, 'دروازے': 1217, 'دستک': 1218, 'جگا': 1219, 'سیمسٹر': 1220, 'آخرکار': 1221, 'بلے': 1222, 'گیندیں': 1223, 'بنائی۔': 1224, 'پریشان': 1225, 'پارک': 1226, 'سٹریٹ': 1227, 'مالک': 1228, 'ہٹ': 1229, 'ہوگی': 1230, 'سستا': 1231, 'تینوں': 1232, 'لڑکوں': 1233, 'اٹھی': 1234, 'قائل': 1235, 'گزارا۔': 1236, 'حامی': 1237, 'بھری۔': 1238, 'لو': 1239, 'اکاؤنٹس': 1240, 'آڈٹ': 1241, 'چابی': 1242, 'وایلن': 1243, 'بجانا': 1244, 'سیکھا؟': 1245, 'رابطہ': 1246, 'پایا۔': 1247, 'مجلس': 1248, 'پڑندے': 1249, 'جہاذ': 1250, 'پہاڑ': 1251, 'گزرا۔': 1252, 'رجوع': 1253, 'ٹریفک': 1254, 'آیا؟': 1255, 'قصبے': 1256, 'حصوں': 1257, 'تقسیم': 1258, 'بوڑھے': 1259, 'کھیلتے': 1260, 'خریدی۔': 1261, 'مطلب': 1262, 'سوچتے': 1263, 'ٹوٹے': 1264, 'شرمندہ': 1265, 'چکے': 1266, 'ہو،': 1267, 'سمجھا۔': 1268, 'ورزش': 1269, 'جشن': 1270, 'لگا؟': 1271, 'سیڑھیاں': 1272, 'چڑھی': 1273, 'بجھ': 1274, 'آندھی': 1275, 'سمندری': 1276, 'اشیائیں': 1277, 'خرچے': 1278, 'کھائو': 1279, 'کرلی': 1280, 'یابی': 1281, 'دھکا': 1282, 'عینک': 1283, 'ٹوٹ': 1284, 'گئ۔': 1285, 'رکو،': 1286, 'آسٹریلوی': 1287, 'لڑکیاں': 1288, 'بھاگنے': 1289, 'نقد': 1290, 'رقم': 1291, 'ادائیگی': 1292, 'کلاس': 1293, 'مریض': 1294, 'لیئے۔': 1295, 'آئِں': 1296, 'پتلی': 1297, 'بالوں': 1298, 'انداز': 1299, 'بھیڑ': 1300, 'منفرد': 1301, 'کھیلوں': 1302, 'باغ': 1303, 'سکا۔': 1304, 'اداس': 1305, 'روک': 1306, 'داپس': 1307, 'لہجے': 1308, 'آنا': 1309, 'صیغہ': 1310, 'پہنچی': 1311, 'گیارہ': 1312, 'بج': 1313, 'ڈائیٹنگ': 1314, 'سکون': 1315, 'خاموشی': 1316, 'کونسے': 1317, 'دانت': 1318, 'مچھلی': 1319, 'الرجی': 1320, 'چودھویں': 1321, 'چاند': 1322, 'بارشوں': 1323, 'ابل': 1324, 'بدلاؤ': 1325, 'جاؤ۔': 1326, 'آنکھ': 1327, 'اندھا': 1328, 'کھاتا': 1329, 'نی': 1330, 'ہیروں': 1331, 'سیب': 1332, 'کڑوا': 1333, 'فیصد': 1334, 'ضیاع': 1335, 'ڈبے': 1336, 'آذاد': 1337, 'نشہ': 1338, 'سٹاپ': 1339, 'پہنچنے': 1340, 'ٹھیٹر': 1341, '۱': 1342, 'میل': 1343, 'چلا۔': 1344, 'انگلی': 1345, 'اشارہ': 1346, 'تمیز': 1347, 'دائرے': 1348, 'وِی': 1349, 'کاافی': 1350, 'ڈھونڈنے': 1351, 'کھلونوں': 1352, 'لکھتا': 1353, 'لائی': 1354, 'روذ': 1355, 'مشق': 1356, 'پہنچتےساتھ': 1357, 'آج؟': 1358, 'نوجوان': 1359, 'علموں': 1360, '۱۸': 1361, '۲۵': 1362, 'جون': 1363, 'دھمکی': 1364, 'اسلحہ': 1365, 'سویا۔': 1366, 'پیوی': 1367, 'لنکلن': 1368, 'الیکشن': 1369, 'ہمسائیوں': 1370, 'ہونگی۔': 1371, 'کشتی': 1372, 'براہ': 1373, 'کرم': 1374, 'دیجیے': 1375, 'شرکت': 1376, 'دجسٹر': 1377, 'جانا۔': 1378, 'طاقتور': 1379, 'لگانا۔': 1380, 'روئے۔': 1381, 'موٹا': 1382, 'سائنس': 1383, 'مقاصد': 1384, 'خرگوش': 1385, 'کان': 1386, 'لمبے': 1387, 'دم': 1388, 'ہوتی': 1389, 'کتابوں': 1390, 'مانگ': 1391, 'پہنچا': 1392, 'آدپی': 1393, 'سہلیاں': 1394, 'چنوں': 1395, 'مسلہ': 1396, 'سچا': 1397, 'باورچی': 1398, 'خانے': 1399, 'قینچیاں': 1400, 'ملی': 1401, 'احساس': 1402, 'تمام': 1403, 'مسائل': 1404, 'زمہ': 1405, 'دار': 1406, 'ٹھہرایا': 1407, 'بجھے': 1408, 'گیٹار': 1409, 'ہوتا،': 1410, 'لیتا۔': 1411, 'کمزور': 1412, 'بھیجتا': 1413, 'عقلمند': 1414, 'لڑکا': 1415, 'کھلی': 1416, 'رکھنا۔': 1417, 'مجبوری': 1418, 'ثابت': 1419, 'خریدی': 1420, 'کامیابی': 1421, 'پہ۔': 1422, 'نا': 1423, 'چاہئہے': 1424, 'یاد۔': 1425, 'کل۔': 1426, 'ملکیوں': 1427, 'معاف': 1428, 'کیجیئے': 1429, 'تھام': 1430, 'کارآمد': 1431, 'پلیز': 1432, 'آجائو۔': 1433, 'معزرت': 1434, 'خواہ': 1435, 'کتوں': 1436, 'آجائے': 1437, 'کوٹ': 1438, 'تھا،': 1439, 'ہلکے': 1440, 'نیلے': 1441, 'ریڈہو': 1442, 'جیئے': 1443, 'مرغی': 1444, 'دال': 1445, 'برابر۔': 1446, 'ہنس': 1447, 'نیند': 1448, 'پھنسا': 1449, 'افراد': 1450, 'پاسورڈس': 1451, 'دکھنے': 1452, 'پڑتے': 1453, 'کہتے': 1454, 'اخلاق': 1455, 'فورا٘': 1456, 'پوئی': 1457, 'کئیے۔': 1458, 'دیتی': 1459, 'تمہیارے': 1460, 'برآمدے': 1461, 'چراغ': 1462, 'پردوں': 1463, 'لگنے': 1464, 'خطرہ': 1465, 'پڑتا۔': 1466, 'صحیص': 1467, 'سویٹر': 1468, 'خریدا': 1469, 'پیر': 1470, 'کیوبا': 1471, 'حیرانی': 1472, 'علم': 1473, 'ٹائے': 1474, 'پہننے': 1475, 'حب': 1476, 'یافتہ': 1477, 'مبارک۔': 1478, 'ایسے': 1479, 'گزارنا': 1480, 'بیہوش': 1481, 'گئی،': 1482, 'گرنے': 1483, 'پکڑنا': 1484, 'پڑا۔': 1485, 'آگئی': 1486, 'مسئلہ': 1487, '۵۹': 1488, 'کھولو۔': 1489, 'رکتی': 1490, 'بیرا': 1491, 'بعد،': 1492, 'متفک': 1493, 'درخت': 1494, 'ناول،': 1495, 'تر،': 1496, 'بورنگ': 1497, 'سچ': 1498, 'چھوٹے': 1499}\n"
     ]
    }
   ],
   "source": [
    "print(target_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "981d9432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train sample: [\"i'll\", 'be', 'sixteen', 'on', 'my', 'next', 'birthday.']\n",
      "X_train_dec sample: ['<SOS>', 'میں', 'اپنی', 'اگلی', 'سالگرہ', 'پر', 'سولہ', 'سال', 'کا', 'ہو', 'جائو', 'گا۔']\n",
      "y_train sample: ['میں', 'اپنی', 'اگلی', 'سالگرہ', 'پر', 'سولہ', 'سال', 'کا', 'ہو', 'جائو', 'گا۔', '<EOS>']\n"
     ]
    }
   ],
   "source": [
    "train_size = int(0.9 * len(source_tokens))\n",
    "\n",
    "X_train_tokens = list(source_tokens[:train_size])\n",
    "X_val_tokens = list(source_tokens[train_size:])\n",
    "\n",
    "X_train_dec_tokens = [\n",
    "    [\"<SOS>\"] + sentence.copy()\n",
    "    for sentence in target_tokens[:train_size]\n",
    "]\n",
    "X_val_dec_tokens = [\n",
    "    [\"<SOS>\"] + sentence.copy()\n",
    "    for sentence in target_tokens[train_size:]\n",
    "]\n",
    "\n",
    "y_train_tokens = [\n",
    "    sentence.copy() + [\"<EOS>\"]\n",
    "    for sentence in target_tokens[:train_size]\n",
    "]\n",
    "y_val_tokens = [\n",
    "    sentence.copy() + [\"<EOS>\"]\n",
    "    for sentence in target_tokens[train_size:]\n",
    "]\n",
    "\n",
    "print(\"X_train sample:\", X_train_tokens[0])\n",
    "print(\"X_train_dec sample:\", X_train_dec_tokens[0])\n",
    "print(\"y_train sample:\", y_train_tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "c75ea3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_tokens(sentence_tokens, max_length=15):\n",
    "    padded_tokens = []\n",
    "    for tokens in sentence_tokens:\n",
    "        if len(tokens) > max_length:\n",
    "            tokens = tokens[:max_length]\n",
    "        else:\n",
    "            tokens = tokens + [\"<PAD>\"] * (max_length - len(tokens))\n",
    "        padded_tokens.append(tokens)\n",
    "    return padded_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "a5df1bc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['میں',\n",
       "  'اپنی',\n",
       "  'اگلی',\n",
       "  'سالگرہ',\n",
       "  'پر',\n",
       "  'سولہ',\n",
       "  'سال',\n",
       "  'کا',\n",
       "  'ہو',\n",
       "  'جائو',\n",
       "  'گا۔',\n",
       "  '<EOS>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>'],\n",
       " ['تمہیں',\n",
       "  'یہاں',\n",
       "  'نہیں',\n",
       "  'کھانا',\n",
       "  'چاہئیے۔',\n",
       "  '<EOS>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>']]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_tokens(y_train_tokens[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "0a2466ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample text: [[2, 41, 1454, 0, 0, 0, 0, 0, 0, 0], [15, 8, 6, 1, 1, 0, 0, 0, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "def to_sequence(sentence_tokens, vocab, max_length=15):\n",
    "    padded_tokens = pad_tokens(sentence_tokens, max_length)\n",
    "    sequences = []\n",
    "    for tokens in padded_tokens:\n",
    "        sequence = [vocab.get(token, vocab[\"<UNK>\"]) for token in tokens]\n",
    "        sequences.append(sequence)\n",
    "    return sequences\n",
    "\n",
    "\n",
    "sample_text = [\"I am happy\", \"This is a test sentence\"]\n",
    "sample_tokens = tokenize(sample_text)\n",
    "sample_sequence = to_sequence(sample_tokens, source_vocab, max_length=10)\n",
    "print(\"Sample text:\", sample_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "fbab0bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train sample: [38, 18, 241, 29, 10, 140, 242, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "y_train_dec sample: [2, 4, 30, 391, 298, 76, 299, 61, 20, 21, 87, 35, 0, 0, 0]\n",
      "y_train sample: [4, 30, 391, 298, 76, 299, 61, 20, 21, 87, 35, 3, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "X_train = to_sequence(X_train_tokens, source_vocab, max_length=15)\n",
    "X_val = to_sequence(X_val_tokens, source_vocab, max_length=15)\n",
    "\n",
    "X_train_dec = to_sequence(X_train_dec_tokens, target_vocab, max_length=15)\n",
    "X_val_dec = to_sequence(X_val_dec_tokens, target_vocab, max_length=15)\n",
    "\n",
    "y_train = to_sequence(y_train_tokens, target_vocab, max_length=15)\n",
    "y_val = to_sequence(y_val_tokens, target_vocab, max_length=15)\n",
    "\n",
    "\n",
    "print(\"X_train sample:\", X_train[0])\n",
    "print(\"y_train_dec sample:\", X_train_dec[0])\n",
    "print(\"y_train sample:\", y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "22f15b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 1034\n",
      "Number of validation samples: 115\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "train_data = TensorDataset(\n",
    "    torch.tensor(X_train, dtype=torch.long),\n",
    "    torch.tensor(X_train_dec, dtype=torch.long),\n",
    "    torch.tensor(y_train, dtype=torch.long),\n",
    ")\n",
    "\n",
    "val_data = TensorDataset(\n",
    "    torch.tensor(X_val, dtype=torch.long),\n",
    "    torch.tensor(X_val_dec, dtype=torch.long),\n",
    "    torch.tensor(y_val, dtype=torch.long),\n",
    ")\n",
    "print(\"Number of training samples:\", len(train_data))\n",
    "print(\"Number of validation samples:\", len(val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "bc9d6267",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "57279f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "b6862c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(nn.Module):\n",
    "    \"\"\"Additive attention mechanism (Bahdanau et al., 2015)\"\"\"\n",
    "\n",
    "    def __init__(self, hidden_size):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        # Linear layers for computing attention scores\n",
    "        self.W_decoder = nn.Linear(hidden_size, hidden_size, bias=False)\n",
    "        self.W_encoder = nn.Linear(hidden_size, hidden_size, bias=False)\n",
    "        self.v = nn.Linear(hidden_size, 1, bias=False)\n",
    "\n",
    "    def forward(self, decoder_hidden, encoder_outputs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            decoder_hidden: (num_layers, batch, hidden_size) - current decoder hidden state\n",
    "            encoder_outputs: (batch, seq_len, hidden_size) - all encoder outputs\n",
    "        Returns:\n",
    "            context: (batch, 1, hidden_size) - weighted sum of encoder outputs\n",
    "            attention_weights: (batch, seq_len) - attention distribution\n",
    "        \"\"\"\n",
    "        # Take only the last layer's hidden state\n",
    "        decoder_hidden = decoder_hidden[-1].unsqueeze(1)  # (batch, 1, hidden_size)\n",
    "\n",
    "        # Compute attention scores\n",
    "        # decoder_hidden: (batch, 1, hidden_size) -> (batch, seq_len, hidden_size)\n",
    "        decoder_hidden = decoder_hidden.repeat(1, encoder_outputs.size(1), 1)\n",
    "\n",
    "        # Additive attention: score = v^T * tanh(W_d * h_d + W_e * h_e)\n",
    "        energy = torch.tanh(\n",
    "            self.W_decoder(decoder_hidden) + self.W_encoder(encoder_outputs)\n",
    "        )  # (batch, seq_len, hidden_size)\n",
    "\n",
    "        attention_scores = self.v(energy).squeeze(2)  # (batch, seq_len)\n",
    "\n",
    "        # Normalize to get attention weights\n",
    "        attention_weights = F.softmax(attention_scores, dim=1)  # (batch, seq_len)\n",
    "\n",
    "        # Compute context vector as weighted sum\n",
    "        context = torch.bmm(\n",
    "            attention_weights.unsqueeze(1), encoder_outputs\n",
    "        )  # (batch, 1, hidden_size)\n",
    "\n",
    "        return context, attention_weights\n",
    "\n",
    "\n",
    "class LuongAttention(nn.Module):\n",
    "    \"\"\"Multiplicative attention mechanism (Luong et al., 2015)\"\"\"\n",
    "\n",
    "    def __init__(self, hidden_size, attention_type=\"dot\"):\n",
    "        super(LuongAttention, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.attention_type = attention_type\n",
    "\n",
    "        if attention_type == \"general\":\n",
    "            self.W = nn.Linear(hidden_size, hidden_size, bias=False)\n",
    "        elif attention_type == \"concat\":\n",
    "            self.W = nn.Linear(hidden_size * 2, hidden_size, bias=False)\n",
    "            self.v = nn.Linear(hidden_size, 1, bias=False)\n",
    "\n",
    "    def forward(self, decoder_hidden, encoder_outputs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            decoder_hidden: (num_layers, batch, hidden_size)\n",
    "            encoder_outputs: (batch, seq_len, hidden_size)\n",
    "        Returns:\n",
    "            context: (batch, 1, hidden_size)\n",
    "            attention_weights: (batch, seq_len)\n",
    "        \"\"\"\n",
    "        # Take only the last layer's hidden state\n",
    "        decoder_hidden = decoder_hidden[-1]  # (batch, hidden_size)\n",
    "\n",
    "        if self.attention_type == \"dot\":\n",
    "            # Dot product: score = h_d^T * h_e\n",
    "            attention_scores = torch.bmm(\n",
    "                decoder_hidden.unsqueeze(1), encoder_outputs.transpose(1, 2)\n",
    "            ).squeeze(\n",
    "                1\n",
    "            )  # (batch, seq_len)\n",
    "\n",
    "        elif self.attention_type == \"general\":\n",
    "            # General: score = h_d^T * W * h_e\n",
    "            transformed_encoder = self.W(\n",
    "                encoder_outputs\n",
    "            )  # (batch, seq_len, hidden_size)\n",
    "            attention_scores = torch.bmm(\n",
    "                decoder_hidden.unsqueeze(1), transformed_encoder.transpose(1, 2)\n",
    "            ).squeeze(\n",
    "                1\n",
    "            )  # (batch, seq_len)\n",
    "\n",
    "        elif self.attention_type == \"concat\":\n",
    "            # Concat: score = v^T * tanh(W * [h_d; h_e])\n",
    "            decoder_hidden_expanded = decoder_hidden.unsqueeze(1).repeat(\n",
    "                1, encoder_outputs.size(1), 1\n",
    "            )  # (batch, seq_len, hidden_size)\n",
    "            combined = torch.cat(\n",
    "                [decoder_hidden_expanded, encoder_outputs], dim=2\n",
    "            )  # (batch, seq_len, 2*hidden_size)\n",
    "            energy = torch.tanh(self.W(combined))  # (batch, seq_len, hidden_size)\n",
    "            attention_scores = self.v(energy).squeeze(2)  # (batch, seq_len)\n",
    "\n",
    "        # Normalize to get attention weights\n",
    "        attention_weights = F.softmax(attention_scores, dim=1)  # (batch, seq_len)\n",
    "\n",
    "        # Compute context vector\n",
    "        context = torch.bmm(\n",
    "            attention_weights.unsqueeze(1), encoder_outputs\n",
    "        )  # (batch, 1, hidden_size)\n",
    "\n",
    "        return context, attention_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "4a0e3b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_vocab_size,\n",
    "        embed_size,\n",
    "        hidden_size,\n",
    "        num_layers=2,\n",
    "        bidirectional=False,\n",
    "    ):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(input_vocab_size, embed_size, padding_idx=0)\n",
    "        self.bidirectional = bidirectional\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gru = nn.GRU(\n",
    "            embed_size,\n",
    "            hidden_size,\n",
    "            num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=bidirectional,\n",
    "            dropout=0.5 if num_layers > 1 else 0,\n",
    "        )\n",
    "        self.embed_dropout = nn.Dropout(0.3)\n",
    "        if bidirectional:\n",
    "            # Project concatenated bidirectional hidden states to decoder size\n",
    "            self.hidden_projection = nn.Linear(hidden_size * 2, hidden_size)\n",
    "            # Project bidirectional outputs to match decoder hidden size\n",
    "            self.output_projection = nn.Linear(hidden_size * 2, hidden_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embed_dropout(self.embedding(x))\n",
    "        outputs, hidden = self.gru(embedded)\n",
    "\n",
    "        if self.bidirectional:\n",
    "            # Project outputs: (batch, seq_len, hidden_size * 2) -> (batch, seq_len, hidden_size)\n",
    "            outputs = self.output_projection(outputs)\n",
    "\n",
    "            # Reshape: (num_layers * 2, batch, hidden) -> (num_layers, 2, batch, hidden)\n",
    "            hidden = hidden.view(self.num_layers, 2, -1, self.hidden_size)\n",
    "            # Concatenate forward and backward\n",
    "            hidden = torch.cat([hidden[:, 0, :, :], hidden[:, 1, :, :]], dim=2)\n",
    "            # Project to decoder size\n",
    "            hidden = self.hidden_projection(hidden)\n",
    "\n",
    "        return outputs, hidden\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        output_vocab_size,\n",
    "        embed_size,\n",
    "        hidden_size,\n",
    "        attention_type=None,\n",
    "        num_layers=2,\n",
    "    ):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.attention_type = attention_type\n",
    "        self.embedding = nn.Embedding(output_vocab_size, embed_size, padding_idx=0)\n",
    "        self.embed_dropout = nn.Dropout(0.3)\n",
    "\n",
    "        # Attention mechanism (only if attention_type is specified)\n",
    "        if attention_type is not None:\n",
    "            if attention_type == \"bahdanau\":\n",
    "                self.attention = BahdanauAttention(hidden_size)\n",
    "            else:  # luong (dot, general, or concat)\n",
    "                self.attention = LuongAttention(hidden_size, attention_type)\n",
    "\n",
    "            # GRU with combined input (embedding + context)\n",
    "            gru_input_size = embed_size + hidden_size\n",
    "            # Output projection layer for attention\n",
    "            self.concat_layer = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        else:\n",
    "            # Standard RNN without attention\n",
    "            gru_input_size = embed_size\n",
    "            self.concat_layer = None\n",
    "\n",
    "        self.gru = nn.GRU(\n",
    "            gru_input_size,\n",
    "            hidden_size,\n",
    "            num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=0.5 if num_layers > 1 else 0,\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x, hidden, encoder_outputs=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: (batch, seq_len) - decoder input tokens\n",
    "            hidden: (num_layers, batch, hidden_size) - initial hidden state\n",
    "            encoder_outputs: (batch, src_seq_len, hidden_size) - encoder outputs (MUST be hidden_size, not bidirectional size)\n",
    "        Returns:\n",
    "            outputs: (batch, seq_len, hidden_size) - decoder outputs\n",
    "            hidden: (num_layers, batch, hidden_size) - final hidden state\n",
    "            attention_weights: (batch, seq_len, src_seq_len) or None - attention weights\n",
    "        \"\"\"\n",
    "        embedded = self.embed_dropout(self.embedding(x))  # (batch, seq_len, embed_size)\n",
    "\n",
    "        # No attention - standard RNN decoder\n",
    "        if self.attention_type is None:\n",
    "            outputs, hidden = self.gru(embedded, hidden)\n",
    "            outputs = self.dropout(outputs)\n",
    "            return outputs, hidden, None\n",
    "\n",
    "        # With attention\n",
    "        batch_size = x.size(0)\n",
    "        seq_len = x.size(1)\n",
    "\n",
    "        outputs = []\n",
    "        all_attention_weights = []\n",
    "\n",
    "        # Process each time step\n",
    "        for t in range(seq_len):\n",
    "            # Get embedding for current time step\n",
    "            embed_t = embedded[:, t : t + 1, :]  # (batch, 1, embed_size)\n",
    "\n",
    "            # Compute attention context\n",
    "            context, attention_weights = self.attention(hidden, encoder_outputs)\n",
    "            all_attention_weights.append(attention_weights)\n",
    "\n",
    "            # Concatenate embedding and context\n",
    "            gru_input = torch.cat(\n",
    "                [embed_t, context], dim=2\n",
    "            )  # (batch, 1, embed_size + hidden_size)\n",
    "\n",
    "            # Pass through GRU\n",
    "            output, hidden = self.gru(\n",
    "                gru_input, hidden\n",
    "            )  # output: (batch, 1, hidden_size)\n",
    "\n",
    "            # Combine GRU output with context (Luong's approach)\n",
    "            combined = torch.cat([output, context], dim=2)  # (batch, 1, 2*hidden_size)\n",
    "            output = torch.tanh(self.concat_layer(combined))  # (batch, 1, hidden_size)\n",
    "            output = self.dropout(output)\n",
    "\n",
    "            outputs.append(output)\n",
    "\n",
    "        # Concatenate all outputs\n",
    "        outputs = torch.cat(outputs, dim=1)  # (batch, seq_len, hidden_size)\n",
    "        attention_weights = torch.stack(\n",
    "            all_attention_weights, dim=1\n",
    "        )  # (batch, seq_len, src_seq_len)\n",
    "\n",
    "        return outputs, hidden, attention_weights\n",
    "\n",
    "\n",
    "class EncoderDecoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.fc = nn.Linear(decoder.hidden_size, len(target_vocab))\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, source, target):\n",
    "        # Get encoder outputs and hidden state\n",
    "        encoder_outputs, encoder_hidden = self.encoder(source)\n",
    "\n",
    "        # Pass encoder outputs to decoder if attention is used\n",
    "        if self.decoder.attention_type is not None:\n",
    "            decoder_outputs, decoder_hidden, attention_weights = self.decoder(\n",
    "                target, encoder_hidden, encoder_outputs\n",
    "            )\n",
    "        else:\n",
    "            # No attention - only pass hidden state\n",
    "            decoder_outputs, decoder_hidden, attention_weights = self.decoder(\n",
    "                target, encoder_hidden, encoder_outputs=None\n",
    "            )\n",
    "\n",
    "        decoder_outputs = self.dropout(decoder_outputs)\n",
    "        return self.fc(decoder_outputs), attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae29cd99",
   "metadata": {},
   "source": [
    "# Training and Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "000a5fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "\n",
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    progress_bar = tqdm.tqdm(dataloader, desc=\"Training\")\n",
    "    for enc_inputs, dec_inputs, targets in progress_bar:\n",
    "        # Move data to device\n",
    "        enc_inputs, dec_inputs, targets = (\n",
    "            enc_inputs.to(device),\n",
    "            dec_inputs.to(device),\n",
    "            targets.to(device),\n",
    "        )\n",
    "\n",
    "        outputs, _ = model(enc_inputs, dec_inputs)\n",
    "        outputs = outputs.reshape(-1, outputs.size(-1))\n",
    "        targets = targets.reshape(-1)\n",
    "\n",
    "        loss = criterion(outputs, targets)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        non_pad_mask = targets != 0  # Create mask for non-padding tokens\n",
    "        total += non_pad_mask.sum().item()\n",
    "        correct += ((predicted == targets) & non_pad_mask).sum().item()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Update progress bar\n",
    "        progress_bar.set_postfix(\n",
    "            {\"loss\": f\"{loss.item():.4f}\", \"acc\": f\"{100 * correct / total:.2f}%\"}\n",
    "        )\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    accuracy = 100 * correct / total\n",
    "\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132a0aad",
   "metadata": {},
   "source": [
    "## Step 11: Validation Function\n",
    "\n",
    "The validation function evaluates the model without updating weights. This helps us monitor overfitting and select the best model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "fe1ea651",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    progress_bar = tqdm.tqdm(dataloader, desc=\"Validating\")\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for enc_inputs, dec_inputs, targets in progress_bar:\n",
    "            # Move data to device\n",
    "            enc_inputs, dec_inputs, targets = (\n",
    "                enc_inputs.to(device),\n",
    "                dec_inputs.to(device),\n",
    "                targets.to(device),\n",
    "            )\n",
    "\n",
    "            outputs, _ = model(enc_inputs, dec_inputs)\n",
    "            outputs = outputs.reshape(-1, outputs.size(-1))\n",
    "            targets = targets.reshape(-1)\n",
    "\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            # Calculate accuracy\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            non_pad_mask = targets != 0  # Create mask for non-padding tokens\n",
    "            total += non_pad_mask.sum().item()\n",
    "            correct += ((predicted == targets) & non_pad_mask).sum().item()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Update progress bar with current accuracy\n",
    "            progress_bar.set_postfix(\n",
    "                {\"loss\": f\"{loss.item():.4f}\", \"acc\": f\"{100 * correct / total:.2f}%\"}\n",
    "            )\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    accuracy = 100 * correct / total\n",
    "\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "8e343101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderDecoder(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(1500, 64, padding_idx=0)\n",
       "    (gru): GRU(64, 256, batch_first=True)\n",
       "    (embed_dropout): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(1500, 64, padding_idx=0)\n",
       "    (embed_dropout): Dropout(p=0.3, inplace=False)\n",
       "    (attention): LuongAttention(\n",
       "      (W): Linear(in_features=256, out_features=256, bias=False)\n",
       "    )\n",
       "    (concat_layer): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (gru): GRU(320, 256, batch_first=True)\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (fc): Linear(in_features=256, out_features=1500, bias=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the models\n",
    "embed_size = 64\n",
    "hidden_size = 256\n",
    "attention_type = 'general'\n",
    "num_layers = 1\n",
    "encoder = Encoder(\n",
    "    len(source_vocab), embed_size, hidden_size, num_layers, bidirectional=False\n",
    ")\n",
    "decoder = Decoder(\n",
    "    len(target_vocab), embed_size, hidden_size, attention_type, num_layers\n",
    ")\n",
    "\n",
    "model = EncoderDecoder(encoder, decoder)\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "a4bbe4db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "EncoderDecoder                           [1, 15, 1500]             --\n",
       "├─Encoder: 1-1                           [1, 15, 256]              --\n",
       "│    └─Embedding: 2-1                    [1, 15, 64]               96,000\n",
       "│    └─Dropout: 2-2                      [1, 15, 64]               --\n",
       "│    └─GRU: 2-3                          [1, 15, 256]              247,296\n",
       "├─Decoder: 1-2                           [1, 15, 256]              --\n",
       "│    └─Embedding: 2-4                    [1, 15, 64]               96,000\n",
       "│    └─Dropout: 2-5                      [1, 15, 64]               --\n",
       "│    └─LuongAttention: 2-6               [1, 1, 256]               --\n",
       "│    │    └─Linear: 3-1                  [1, 15, 256]              65,536\n",
       "│    └─GRU: 2-7                          [1, 1, 256]               443,904\n",
       "│    └─Linear: 2-8                       [1, 1, 256]               131,328\n",
       "│    └─Dropout: 2-9                      [1, 1, 256]               --\n",
       "│    └─LuongAttention: 2-10              [1, 1, 256]               (recursive)\n",
       "│    │    └─Linear: 3-2                  [1, 15, 256]              (recursive)\n",
       "│    └─GRU: 2-11                         [1, 1, 256]               (recursive)\n",
       "│    └─Linear: 2-12                      [1, 1, 256]               (recursive)\n",
       "│    └─Dropout: 2-13                     [1, 1, 256]               --\n",
       "│    └─LuongAttention: 2-14              [1, 1, 256]               (recursive)\n",
       "│    │    └─Linear: 3-3                  [1, 15, 256]              (recursive)\n",
       "│    └─GRU: 2-15                         [1, 1, 256]               (recursive)\n",
       "│    └─Linear: 2-16                      [1, 1, 256]               (recursive)\n",
       "│    └─Dropout: 2-17                     [1, 1, 256]               --\n",
       "│    └─LuongAttention: 2-18              [1, 1, 256]               (recursive)\n",
       "│    │    └─Linear: 3-4                  [1, 15, 256]              (recursive)\n",
       "│    └─GRU: 2-19                         [1, 1, 256]               (recursive)\n",
       "│    └─Linear: 2-20                      [1, 1, 256]               (recursive)\n",
       "│    └─Dropout: 2-21                     [1, 1, 256]               --\n",
       "│    └─LuongAttention: 2-22              [1, 1, 256]               (recursive)\n",
       "│    │    └─Linear: 3-5                  [1, 15, 256]              (recursive)\n",
       "│    └─GRU: 2-23                         [1, 1, 256]               (recursive)\n",
       "│    └─Linear: 2-24                      [1, 1, 256]               (recursive)\n",
       "│    └─Dropout: 2-25                     [1, 1, 256]               --\n",
       "│    └─LuongAttention: 2-26              [1, 1, 256]               (recursive)\n",
       "│    │    └─Linear: 3-6                  [1, 15, 256]              (recursive)\n",
       "│    └─GRU: 2-27                         [1, 1, 256]               (recursive)\n",
       "│    └─Linear: 2-28                      [1, 1, 256]               (recursive)\n",
       "│    └─Dropout: 2-29                     [1, 1, 256]               --\n",
       "│    └─LuongAttention: 2-30              [1, 1, 256]               (recursive)\n",
       "│    │    └─Linear: 3-7                  [1, 15, 256]              (recursive)\n",
       "│    └─GRU: 2-31                         [1, 1, 256]               (recursive)\n",
       "│    └─Linear: 2-32                      [1, 1, 256]               (recursive)\n",
       "│    └─Dropout: 2-33                     [1, 1, 256]               --\n",
       "│    └─LuongAttention: 2-34              [1, 1, 256]               (recursive)\n",
       "│    │    └─Linear: 3-8                  [1, 15, 256]              (recursive)\n",
       "│    └─GRU: 2-35                         [1, 1, 256]               (recursive)\n",
       "│    └─Linear: 2-36                      [1, 1, 256]               (recursive)\n",
       "│    └─Dropout: 2-37                     [1, 1, 256]               --\n",
       "│    └─LuongAttention: 2-38              [1, 1, 256]               (recursive)\n",
       "│    │    └─Linear: 3-9                  [1, 15, 256]              (recursive)\n",
       "│    └─GRU: 2-39                         [1, 1, 256]               (recursive)\n",
       "│    └─Linear: 2-40                      [1, 1, 256]               (recursive)\n",
       "│    └─Dropout: 2-41                     [1, 1, 256]               --\n",
       "│    └─LuongAttention: 2-42              [1, 1, 256]               (recursive)\n",
       "│    │    └─Linear: 3-10                 [1, 15, 256]              (recursive)\n",
       "│    └─GRU: 2-43                         [1, 1, 256]               (recursive)\n",
       "│    └─Linear: 2-44                      [1, 1, 256]               (recursive)\n",
       "│    └─Dropout: 2-45                     [1, 1, 256]               --\n",
       "│    └─LuongAttention: 2-46              [1, 1, 256]               (recursive)\n",
       "│    │    └─Linear: 3-11                 [1, 15, 256]              (recursive)\n",
       "│    └─GRU: 2-47                         [1, 1, 256]               (recursive)\n",
       "│    └─Linear: 2-48                      [1, 1, 256]               (recursive)\n",
       "│    └─Dropout: 2-49                     [1, 1, 256]               --\n",
       "│    └─LuongAttention: 2-50              [1, 1, 256]               (recursive)\n",
       "│    │    └─Linear: 3-12                 [1, 15, 256]              (recursive)\n",
       "│    └─GRU: 2-51                         [1, 1, 256]               (recursive)\n",
       "│    └─Linear: 2-52                      [1, 1, 256]               (recursive)\n",
       "│    └─Dropout: 2-53                     [1, 1, 256]               --\n",
       "│    └─LuongAttention: 2-54              [1, 1, 256]               (recursive)\n",
       "│    │    └─Linear: 3-13                 [1, 15, 256]              (recursive)\n",
       "│    └─GRU: 2-55                         [1, 1, 256]               (recursive)\n",
       "│    └─Linear: 2-56                      [1, 1, 256]               (recursive)\n",
       "│    └─Dropout: 2-57                     [1, 1, 256]               --\n",
       "│    └─LuongAttention: 2-58              [1, 1, 256]               (recursive)\n",
       "│    │    └─Linear: 3-14                 [1, 15, 256]              (recursive)\n",
       "│    └─GRU: 2-59                         [1, 1, 256]               (recursive)\n",
       "│    └─Linear: 2-60                      [1, 1, 256]               (recursive)\n",
       "│    └─Dropout: 2-61                     [1, 1, 256]               --\n",
       "│    └─LuongAttention: 2-62              [1, 1, 256]               (recursive)\n",
       "│    │    └─Linear: 3-15                 [1, 15, 256]              (recursive)\n",
       "│    └─GRU: 2-63                         [1, 1, 256]               (recursive)\n",
       "│    └─Linear: 2-64                      [1, 1, 256]               (recursive)\n",
       "│    └─Dropout: 2-65                     [1, 1, 256]               --\n",
       "├─Dropout: 1-3                           [1, 15, 256]              --\n",
       "├─Linear: 1-4                            [1, 15, 1500]             385,500\n",
       "==========================================================================================\n",
       "Total params: 1,465,564\n",
       "Trainable params: 1,465,564\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 13.90\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.75\n",
       "Params size (MB): 5.86\n",
       "Estimated Total Size (MB): 6.61\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "input_sample = torch.zeros((1, 15), dtype=torch.long).to(device)\n",
    "summary(model, input_data=(input_sample, input_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "c5eba591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training batches: 65\n",
      "Number of validation batches: 8\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "# Loss function (ignore padding tokens)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "\n",
    "# Optimizer\n",
    "learning_rate = 0.001\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode=\"min\", factor=0.5, patience=5\n",
    ")\n",
    "\n",
    "print(f\"Number of training batches: {len(train_loader)}\")\n",
    "print(f\"Number of validation batches: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "e47ded53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Device: cuda\n",
      "Number of epochs: 100\n",
      "\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 65/65 [00:09<00:00,  6.82it/s, loss=5.4506, acc=12.50%]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 19.26it/s, loss=4.7254, acc=19.02%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved best model (Val Acc: 19.02%)\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 65/65 [00:10<00:00,  6.10it/s, loss=5.2321, acc=16.15%]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 23.79it/s, loss=4.3902, acc=21.30%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved best model (Val Acc: 21.30%)\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 65/65 [00:09<00:00,  7.13it/s, loss=5.1133, acc=18.25%]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 17.92it/s, loss=4.1457, acc=22.61%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved best model (Val Acc: 22.61%)\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 65/65 [00:09<00:00,  7.19it/s, loss=4.6413, acc=21.08%]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 21.26it/s, loss=3.7349, acc=26.30%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved best model (Val Acc: 26.30%)\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 65/65 [00:09<00:00,  6.63it/s, loss=4.3858, acc=23.53%]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 22.14it/s, loss=3.4344, acc=26.41%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved best model (Val Acc: 26.41%)\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 65/65 [00:10<00:00,  6.00it/s, loss=4.7023, acc=25.17%]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 14.77it/s, loss=3.2521, acc=29.35%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved best model (Val Acc: 29.35%)\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 65/65 [00:10<00:00,  6.28it/s, loss=3.8844, acc=26.99%]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 21.54it/s, loss=3.2368, acc=31.09%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved best model (Val Acc: 31.09%)\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 65/65 [00:10<00:00,  5.93it/s, loss=3.7879, acc=28.97%]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 20.21it/s, loss=2.9183, acc=32.17%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved best model (Val Acc: 32.17%)\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 65/65 [00:10<00:00,  6.18it/s, loss=3.9889, acc=31.14%]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 20.03it/s, loss=2.7032, acc=35.11%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved best model (Val Acc: 35.11%)\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 65/65 [00:10<00:00,  6.29it/s, loss=3.9767, acc=33.53%]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 21.97it/s, loss=2.7368, acc=33.91%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 65/65 [00:09<00:00,  7.00it/s, loss=3.2743, acc=35.79%]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 22.04it/s, loss=2.5959, acc=36.41%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved best model (Val Acc: 36.41%)\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 65/65 [00:09<00:00,  6.62it/s, loss=3.3248, acc=37.61%]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 23.10it/s, loss=2.4527, acc=37.07%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved best model (Val Acc: 37.07%)\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 65/65 [00:09<00:00,  7.09it/s, loss=3.4518, acc=40.69%]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 14.81it/s, loss=2.3177, acc=36.30%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 65/65 [00:08<00:00,  7.46it/s, loss=2.5559, acc=42.41%]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 21.49it/s, loss=2.3038, acc=37.93%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved best model (Val Acc: 37.93%)\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 65/65 [00:09<00:00,  6.52it/s, loss=2.3374, acc=44.65%]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 20.96it/s, loss=2.3881, acc=39.67%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved best model (Val Acc: 39.67%)\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 65/65 [00:10<00:00,  6.47it/s, loss=2.1705, acc=47.49%]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 24.40it/s, loss=2.2143, acc=41.09%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved best model (Val Acc: 41.09%)\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 65/65 [00:08<00:00,  7.64it/s, loss=2.2432, acc=49.79%]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 25.08it/s, loss=2.3670, acc=41.85%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved best model (Val Acc: 41.85%)\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 65/65 [00:10<00:00,  6.45it/s, loss=2.4011, acc=52.78%]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 24.96it/s, loss=2.2521, acc=43.59%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved best model (Val Acc: 43.59%)\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 65/65 [00:10<00:00,  6.20it/s, loss=2.0218, acc=54.96%]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 11.46it/s, loss=2.2192, acc=43.26%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 65/65 [00:11<00:00,  5.73it/s, loss=2.2301, acc=56.89%]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 28.09it/s, loss=2.2458, acc=44.57%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved best model (Val Acc: 44.57%)\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 65/65 [00:09<00:00,  6.79it/s, loss=1.8818, acc=58.74%]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 20.15it/s, loss=2.2822, acc=43.91%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 65/65 [00:09<00:00,  7.04it/s, loss=1.3242, acc=61.58%]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 24.22it/s, loss=2.3222, acc=44.24%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 65/65 [00:08<00:00,  7.77it/s, loss=1.8317, acc=63.54%]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 29.07it/s, loss=2.1946, acc=45.87%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved best model (Val Acc: 45.87%)\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 65/65 [00:09<00:00,  7.01it/s, loss=1.5315, acc=65.12%]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 23.91it/s, loss=2.1833, acc=44.67%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 65/65 [00:09<00:00,  6.94it/s, loss=1.6440, acc=67.12%]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 27.37it/s, loss=2.1222, acc=45.98%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved best model (Val Acc: 45.98%)\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 65/65 [00:08<00:00,  8.04it/s, loss=1.2274, acc=68.65%]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 25.08it/s, loss=2.0272, acc=46.96%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved best model (Val Acc: 46.96%)\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 65/65 [00:08<00:00,  7.86it/s, loss=1.1804, acc=70.58%]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 24.74it/s, loss=2.2235, acc=46.52%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 65/65 [00:08<00:00,  7.25it/s, loss=1.2526, acc=70.37%]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 18.90it/s, loss=2.2747, acc=46.85%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 65/65 [00:08<00:00,  7.22it/s, loss=1.3167, acc=73.53%]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 25.17it/s, loss=2.2057, acc=48.59%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved best model (Val Acc: 48.59%)\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 65/65 [00:08<00:00,  7.53it/s, loss=1.0080, acc=76.32%]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 27.51it/s, loss=2.0836, acc=48.37%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 65/65 [00:08<00:00,  8.01it/s, loss=0.8338, acc=78.17%]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 31.12it/s, loss=2.2020, acc=48.26%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 65/65 [00:06<00:00,  9.82it/s, loss=0.8936, acc=78.72%]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 28.45it/s, loss=2.0330, acc=48.15%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 65/65 [00:06<00:00, 10.00it/s, loss=0.8187, acc=79.40%]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 34.62it/s, loss=2.2066, acc=48.70%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved best model (Val Acc: 48.70%)\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 65/65 [00:07<00:00,  8.56it/s, loss=1.0987, acc=79.96%]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 25.99it/s, loss=2.1685, acc=47.83%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 65/65 [00:07<00:00,  8.60it/s, loss=0.9104, acc=80.91%]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 25.84it/s, loss=2.0412, acc=48.15%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 65/65 [00:08<00:00,  7.84it/s, loss=0.6543, acc=81.85%]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 22.06it/s, loss=2.1216, acc=47.61%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 65/65 [00:10<00:00,  6.41it/s, loss=0.7764, acc=82.56%]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 20.25it/s, loss=2.1036, acc=48.37%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 65/65 [00:09<00:00,  6.86it/s, loss=0.7144, acc=83.29%]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 15.56it/s, loss=2.1482, acc=47.93%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 65/65 [00:07<00:00,  8.25it/s, loss=0.8981, acc=83.65%]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 25.88it/s, loss=2.0802, acc=48.15%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 65/65 [00:07<00:00,  8.94it/s, loss=0.7820, acc=82.76%]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 25.58it/s, loss=2.1010, acc=47.50%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 65/65 [00:07<00:00,  8.85it/s, loss=0.6016, acc=84.20%]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 25.77it/s, loss=2.1609, acc=48.37%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 65/65 [00:07<00:00,  8.98it/s, loss=0.8675, acc=84.25%]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 25.86it/s, loss=2.1583, acc=48.80%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved best model (Val Acc: 48.80%)\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 65/65 [00:08<00:00,  7.54it/s, loss=0.7285, acc=84.59%]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 19.01it/s, loss=2.1267, acc=48.37%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 65/65 [00:08<00:00,  7.96it/s, loss=0.6321, acc=84.34%]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 25.65it/s, loss=2.1263, acc=48.48%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 65/65 [00:07<00:00,  8.90it/s, loss=0.7260, acc=85.00%]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 26.12it/s, loss=2.1724, acc=48.48%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 65/65 [00:07<00:00,  8.99it/s, loss=0.5730, acc=85.37%]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 28.10it/s, loss=2.1603, acc=48.48%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 65/65 [00:07<00:00,  8.72it/s, loss=0.7942, acc=85.16%]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 26.80it/s, loss=2.1514, acc=48.37%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 65/65 [00:07<00:00,  8.88it/s, loss=0.6889, acc=85.00%]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 21.13it/s, loss=2.1646, acc=47.83%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 65/65 [00:07<00:00,  9.03it/s, loss=0.5186, acc=85.60%]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 19.49it/s, loss=2.1627, acc=48.26%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 65/65 [00:07<00:00,  8.83it/s, loss=0.6792, acc=85.94%]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 26.08it/s, loss=2.1783, acc=48.37%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 65/65 [00:07<00:00,  8.95it/s, loss=0.7499, acc=85.97%]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 26.27it/s, loss=2.1934, acc=48.37%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 65/65 [00:07<00:00,  9.00it/s, loss=0.6229, acc=86.18%]\n",
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 27.68it/s, loss=2.2033, acc=48.80%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 52 epochs\n",
      "Training complete!\n",
      "Best validation accuracy: 48.80%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "best_val_acc = 0.0\n",
    "patience = 10\n",
    "patience_counter = 0\n",
    "\n",
    "# Track training history\n",
    "train_losses = []\n",
    "train_accs = []\n",
    "val_losses = []\n",
    "val_accs = []\n",
    "\n",
    "print(\"Starting training...\")\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"Number of epochs: {num_epochs}\\n\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    # Train\n",
    "    train_loss, train_acc = train_epoch(\n",
    "        model, train_loader, criterion, optimizer, device\n",
    "    )\n",
    "    # Validate\n",
    "    val_loss, val_acc = validate(model, val_loader, criterion, device)\n",
    "\n",
    "    # Track history\n",
    "    train_losses.append(train_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accs.append(val_acc)\n",
    "    \n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    # Save best model\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), \"nmt_model.pth\")\n",
    "        print(f\"  ✓ Saved best model (Val Acc: {val_acc:.2f}%)\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping triggered after {epoch + 1} epochs\")\n",
    "            break\n",
    "\n",
    "print(\"Training complete!\")\n",
    "print(f\"Best validation accuracy: {best_val_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cda3b4",
   "metadata": {},
   "source": [
    "# Load Best Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "a68efb4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:   0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 8/8 [00:00<00:00, 27.81it/s, loss=2.1583, acc=48.80%]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3.3357225358486176, 48.80434782608695)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"nmt_model.pth\", weights_only=True))\n",
    "model = model.to(device)\n",
    "validate(model, val_loader, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "1cae50ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing translations:\n",
      "\n",
      "Source: I'll be sixteen on my next birthday.\n",
      "Target: میں اپنی اگلی سالگرہ پر سولہ سال ہو گی۔\n",
      "\n",
      "Source: You shouldn't eat here.\n",
      "Target: تم ٹھیک ہو۔\n",
      "\n",
      "Source: They became citizens of Japan.\n",
      "Target: انہوں نے جاپانی شہریت حاصل کرلی۔\n",
      "\n",
      "Source: You need to study more.\n",
      "Target: تم کیسے ہو۔\n",
      "\n",
      "Source: I can't do this to Tom.\n",
      "Target: میں یہ کرنا ہوں۔\n",
      "\n",
      "Source: Please wait till he comes back.\n",
      "Target: برائے مہربانی اونچا بولے۔\n",
      "\n",
      "Source: Wolves don't usually attack people.\n",
      "Target: بھیڑیے جانے لوگوں\n",
      "\n",
      "Source: I've been foolish.\n",
      "Target: مجھے لگ رہا ہے۔\n",
      "\n",
      "Source: I can't remember the melody of that song.\n",
      "Target: میں نے اس گیت کا فرانسیسی ہے۔\n",
      "\n",
      "Source: Tom is only a beginner.\n",
      "Target: ٹام کو بہت خوبصورت ہے۔\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_i2t = {idx: token for token, idx in target_vocab.items()}\n",
    "\n",
    "\n",
    "def translate(sentence, model, source_vocab, target_vocab, max_length=20, device=\"cpu\"):\n",
    "    model.eval()\n",
    "    sentence_tokens = sentence.lower().split()\n",
    "    sequence = to_sequence([sentence_tokens], source_vocab, max_length=max_length)\n",
    "    encoder_input = torch.tensor(sequence, dtype=torch.long).to(device)\n",
    "\n",
    "    # Start with <SOS> token\n",
    "    decoder_input = [target_vocab[\"<SOS>\"]]\n",
    "    translation = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Get encoder outputs and hidden state\n",
    "        encoder_outputs, encoder_hidden = model.encoder(encoder_input)\n",
    "\n",
    "        for _ in range(max_length):\n",
    "            # Prepare decoder input\n",
    "            dec_input = torch.tensor([decoder_input], dtype=torch.long).to(device)\n",
    "\n",
    "            # Decode - pass encoder_outputs if attention is used\n",
    "            if model.decoder.attention_type is not None:\n",
    "                decoder_outputs, encoder_hidden, _ = model.decoder(\n",
    "                    dec_input, encoder_hidden, encoder_outputs\n",
    "                )\n",
    "            else:\n",
    "                decoder_outputs, encoder_hidden, _ = model.decoder(\n",
    "                    dec_input, encoder_hidden, encoder_outputs=None\n",
    "                )\n",
    "\n",
    "            # Get prediction for the last token\n",
    "            output = model.fc(decoder_outputs[:, -1, :])\n",
    "            predicted_id = output.argmax(dim=-1).item()\n",
    "\n",
    "            # Check for EOS token\n",
    "            if predicted_id == target_vocab[\"<EOS>\"]:\n",
    "                break\n",
    "\n",
    "            # Get the predicted word\n",
    "            predicted_word = target_i2t.get(predicted_id, \"\")\n",
    "\n",
    "            # Skip special tokens in output\n",
    "            if predicted_word not in [\"<PAD>\", \"<UNK>\", \"<SOS>\", \"<EOS>\"]:\n",
    "                translation.append(predicted_word)\n",
    "\n",
    "            # Add predicted token to decoder input for next iteration\n",
    "            decoder_input.append(predicted_id)\n",
    "\n",
    "    return \" \".join(translation)\n",
    "\n",
    "\n",
    "# Test the translation function\n",
    "test_sentences = source_sentences[:10]\n",
    "\n",
    "print(\"Testing translations:\\n\")\n",
    "for sentence in test_sentences:\n",
    "    translated = translate(sentence, model, source_vocab, target_vocab, device=device)\n",
    "    print(f\"Source: {sentence}\")\n",
    "    print(f\"Target: {translated}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ul-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
