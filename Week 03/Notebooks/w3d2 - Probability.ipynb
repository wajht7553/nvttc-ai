{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cce0b3e7",
   "metadata": {},
   "source": [
    "# Summer of Code - Artificial Intelligence\n",
    "## Week 03: Descriptive Statistics and Probability\n",
    "### Day 02: Probability\n",
    "\n",
    "In this notebook, we will explore the fundamental concepts of **probability** that form the backbone of machine learning and data science."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1fbe83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import warnings\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm, binom, poisson, uniform, expon\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d59bddd",
   "metadata": {},
   "source": [
    "# What is Probability?\n",
    "\n",
    "**Probability** is a measure of the likelihood that an event will occur. It's expressed as a number between 0 and 1, where:\n",
    "- **0** means the event will never occur (impossible)\n",
    "- **1** means the event will always occur (certain)\n",
    "- **0.5** means the event is equally likely to occur or not occur\n",
    "\n",
    "*following are to be included in slides*\n",
    "### Key Concepts\n",
    "\n",
    "1. **Sample Space (S)**: The set of all possible outcomes of an experiment\n",
    "2. **Event (E)**: A subset of the sample space\n",
    "3. **Probability of an Event**: P(E) = Number of favorable outcomes / Total number of possible outcomes\n",
    "\n",
    "### Probability Axioms (Kolmogorov Axioms)\n",
    "\n",
    "1. **Non-negativity**: P(A) ≥ 0 for any event A\n",
    "2. **Normalization**: P(S) = 1 (probability of sample space is 1)\n",
    "3. **Additivity**: For mutually exclusive events A and B, P(A ∪ B) = P(A) + P(B)\n",
    "\n",
    "Let's explore these concepts with practical examples!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9626f194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Rolling a Fair Die\n",
    "print(\"=== Example 1: Rolling a Fair Die ===\")\n",
    "print()\n",
    "\n",
    "# Sample space for rolling a die\n",
    "sample_space = [1, 2, 3, 4, 5, 6]\n",
    "print(f\"Sample Space: {sample_space}\")\n",
    "print(f\"Total number of outcomes: {len(sample_space)}\")\n",
    "print()\n",
    "\n",
    "# Probability of rolling an even number\n",
    "even_numbers = [2, 4, 6]\n",
    "prob_even = len(even_numbers) / len(sample_space)\n",
    "print(f\"Even numbers: {even_numbers}\")\n",
    "print(f\"P(Even number) = {len(even_numbers)}/{len(sample_space)} = {prob_even:.2f}\")\n",
    "print()\n",
    "\n",
    "# Probability of rolling a number greater than 4\n",
    "greater_than_4 = [5, 6]\n",
    "prob_greater_than_4 = len(greater_than_4) / len(sample_space)\n",
    "print(f\"Numbers > 4: {greater_than_4}\")\n",
    "print(f\"P(Number > 4) = {len(greater_than_4)}/{len(sample_space)} = {prob_greater_than_4:.2f}\")\n",
    "print()\n",
    "\n",
    "# Example 2: Coin Toss\n",
    "print(\"=== Example 2: Coin Toss ===\")\n",
    "print()\n",
    "\n",
    "# Sample space for coin toss\n",
    "coin_sample_space = ['H', 'T']  # H = Heads, T = Tails\n",
    "print(f\"Sample Space: {coin_sample_space}\")\n",
    "print(\"P(Heads) = 1/2 = 0.5\")\n",
    "print(\"P(Tails) = 1/2 = 0.5\")\n",
    "print(\"P(Heads) + P(Tails) = 0.5 + 0.5 = 1.0 ✓\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a31a1c",
   "metadata": {},
   "source": [
    "# Joint, Marginal, and Conditional Probability\n",
    "\n",
    "## Joint Probability\n",
    "\n",
    "**Joint Probability** $\\text{P(A}\\cap \\text{B)}$ is the probability that both events A and B occur simultaneously.\n",
    "\n",
    "**Formula**: $\\text{P(A}\\cap \\text{B) = P(A and B)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3779aa",
   "metadata": {},
   "source": [
    "## Marginal Probability\n",
    "\n",
    "**Marginal Probability** is the probability of a single event occurring, regardless of other events. It's obtained by summing the joint probabilities across all possible values of the other variable.\n",
    "\n",
    "**Formula**: $\\text{P(A)} = \\sum \\text{P(A} \\cap \\text{B) for all B}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421345c1",
   "metadata": {},
   "source": [
    "## Conditional Probability\n",
    "\n",
    "**Conditional Probability** $\\text{P(A}\\vert\\text{B)}$ is the probability of event A occurring given that event B has already occurred.\n",
    "\n",
    "**Formula**: $\\text{P(A}\\vert\\text{B)} = \\frac{\\text{P(A}\\cap\\text{B)}}{\\text{P(B)}}$\n",
    "\n",
    "### Independence\n",
    "\n",
    "Two events A and B are **independent** if:\n",
    "P(A ∩ B) = P(A) × P(B)\n",
    "\n",
    "This means: P(A|B) = P(A) and P(B|A) = P(B)\n",
    "\n",
    "Let's explore these concepts with a practical example!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6706c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Student Survey Data\n",
    "print(\"=== Example: Student Survey Data ===\")\n",
    "print()\n",
    "\n",
    "# Let's create a contingency table for student preferences\n",
    "# Rows: Gender (M/F), Columns: Subject Preference (Math/Science/Arts)\n",
    "\n",
    "# Joint probabilities (given data)\n",
    "joint_probs = {\n",
    "    (\"Male\", \"Math\"): 0.15,\n",
    "    (\"Male\", \"Science\"): 0.20,\n",
    "    (\"Male\", \"Arts\"): 0.10,\n",
    "    (\"Female\", \"Math\"): 0.10,\n",
    "    (\"Female\", \"Science\"): 0.25,\n",
    "    (\"Female\", \"Arts\"): 0.20,\n",
    "}\n",
    "\n",
    "print(\"Joint Probability Table:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"{'Gender':<8} {'Math':<8} {'Science':<10} {'Arts':<8}\")\n",
    "print(\"-\" * 50)\n",
    "print(\n",
    "    f\"{'Male':<8} {joint_probs[('Male', 'Math')]:<8.2f} {joint_probs[('Male', 'Science')]:<10.2f} {joint_probs[('Male', 'Arts')]:<8.2f}\"\n",
    ")\n",
    "print(\n",
    "    f\"{'Female':<8} {joint_probs[('Female', 'Math')]:<8.2f} {joint_probs[('Female', 'Science')]:<10.2f} {joint_probs[('Female', 'Arts')]:<8.2f}\"\n",
    ")\n",
    "print()\n",
    "\n",
    "# Calculate marginal probabilities\n",
    "print(\"Marginal Probabilities:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Marginal probabilities for Gender\n",
    "P_Male = (\n",
    "    joint_probs[(\"Male\", \"Math\")]\n",
    "    + joint_probs[(\"Male\", \"Science\")]\n",
    "    + joint_probs[(\"Male\", \"Arts\")]\n",
    ")\n",
    "P_Female = (\n",
    "    joint_probs[(\"Female\", \"Math\")]\n",
    "    + joint_probs[(\"Female\", \"Science\")]\n",
    "    + joint_probs[(\"Female\", \"Arts\")]\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"P(Male) = {joint_probs[('Male', 'Math')]:.2f} + {joint_probs[('Male', 'Science')]:.2f} + {joint_probs[('Male', 'Arts')]:.2f} = {P_Male:.2f}\"\n",
    ")\n",
    "print(\n",
    "    f\"P(Female) = {joint_probs[('Female', 'Math')]:.2f} + {joint_probs[('Female', 'Science')]:.2f} + {joint_probs[('Female', 'Arts')]:.2f} = {P_Female:.2f}\"\n",
    ")\n",
    "print()\n",
    "\n",
    "# Marginal probabilities for Subject\n",
    "P_Math = joint_probs[(\"Male\", \"Math\")] + joint_probs[(\"Female\", \"Math\")]\n",
    "P_Science = joint_probs[(\"Male\", \"Science\")] + joint_probs[(\"Female\", \"Science\")]\n",
    "P_Arts = joint_probs[(\"Male\", \"Arts\")] + joint_probs[(\"Female\", \"Arts\")]\n",
    "\n",
    "print(\n",
    "    f\"P(Math) = {joint_probs[('Male', 'Math')]:.2f} + {joint_probs[('Female', 'Math')]:.2f} = {P_Math:.2f}\"\n",
    ")\n",
    "print(\n",
    "    f\"P(Science) = {joint_probs[('Male', 'Science')]:.2f} + {joint_probs[('Female', 'Science')]:.2f} = {P_Science:.2f}\"\n",
    ")\n",
    "print(\n",
    "    f\"P(Arts) = {joint_probs[('Male', 'Arts')]:.2f} + {joint_probs[('Female', 'Arts')]:.2f} = {P_Arts:.2f}\"\n",
    ")\n",
    "print()\n",
    "\n",
    "# Verify that probabilities sum to 1\n",
    "total_prob = P_Male + P_Female\n",
    "print(\n",
    "    f\"Verification: P(Male) + P(Female) = {P_Male:.2f} + {P_Female:.2f} = {total_prob:.2f} ✓\"\n",
    ")\n",
    "print()\n",
    "\n",
    "# Calculate conditional probabilities\n",
    "print(\"Conditional Probabilities:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# P(Math|Male) = P(Math ∩ Male) / P(Male)\n",
    "P_Math_given_Male = joint_probs[(\"Male\", \"Math\")] / P_Male\n",
    "print(\n",
    "    f\"P(Math|Male) = P(Math ∩ Male) / P(Male) = {joint_probs[('Male', 'Math')]:.2f} / {P_Male:.2f} = {P_Math_given_Male:.2f}\"\n",
    ")\n",
    "\n",
    "# P(Science|Female) = P(Science ∩ Female) / P(Female)\n",
    "P_Science_given_Female = joint_probs[(\"Female\", \"Science\")] / P_Female\n",
    "print(\n",
    "    f\"P(Science|Female) = P(Science ∩ Female) / P(Female) = {joint_probs[('Female', 'Science')]:.2f} / {P_Female:.2f} = {P_Science_given_Female:.2f}\"\n",
    ")\n",
    "\n",
    "# P(Female|Arts) = P(Female ∩ Arts) / P(Arts)\n",
    "P_Female_given_Arts = joint_probs[(\"Female\", \"Arts\")] / P_Arts\n",
    "print(\n",
    "    f\"P(Female|Arts) = P(Female ∩ Arts) / P(Arts) = {joint_probs[('Female', 'Arts')]:.2f} / {P_Arts:.2f} = {P_Female_given_Arts:.2f}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102e08c0",
   "metadata": {},
   "source": [
    "# Probability Distributions\n",
    "\n",
    "A **probability distribution** describes how probabilities are distributed over the values of a random variable. It provides a complete description of the probability structure of a random phenomenon.\n",
    "\n",
    "\n",
    "*To be included in the presentation*\n",
    "### Key Components\n",
    "\n",
    "1. **Random Variable (X)**: A variable whose possible values are outcomes of a random phenomenon\n",
    "2. **Probability Mass Function (PMF)**: For discrete variables, gives P(X = x)\n",
    "3. **Probability Density Function (PDF)**: For continuous variables, gives the density at point x\n",
    "4. **Cumulative Distribution Function (CDF)**: Gives P(X ≤ x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d88056",
   "metadata": {},
   "source": [
    "## Discrete Probability Distributions\n",
    "\n",
    "### Binomial Distribution\n",
    "\n",
    "The **Binomial Distribution** models the number of successes in n independent Bernoulli trials.\n",
    "\n",
    "**Parameters**:\n",
    "- n: number of trials\n",
    "- p: probability of success in each trial\n",
    "\n",
    "**Example**: Flipping a coin 10 times, counting heads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3267d114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binomial Distribution Example\n",
    "print(\"=== Binomial Distribution ===\")\n",
    "print()\n",
    "\n",
    "# Parameters\n",
    "n = 10  # number of trials\n",
    "p = 0.5  # probability of success (fair coin)\n",
    "\n",
    "# Generate binomial distribution\n",
    "k_values = np.arange(0, n + 1)\n",
    "binomial_probs = binom.pmf(k_values, n, p)\n",
    "\n",
    "print(f\"Parameters: n = {n}, p = {p}\")\n",
    "print(f\"Mean: μ = n×p = {n}×{p} = {n*p}\")\n",
    "print(f\"Variance: σ² = n×p×(1-p) = {n}×{p}×{1-p} = {n*p*(1-p):.2f}\")\n",
    "print(f\"Standard Deviation: σ = √(n×p×(1-p)) = {np.sqrt(n*p*(1-p)):.2f}\")\n",
    "print()\n",
    "\n",
    "# Display probabilities\n",
    "print(\"Probability Mass Function:\")\n",
    "print(\"=\" * 40)\n",
    "for k, prob in zip(k_values, binomial_probs):\n",
    "    print(f\"P(X = {k:2d}) = {prob:.4f}\")\n",
    "\n",
    "# Visualization\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# PMF Plot\n",
    "ax1.bar(k_values, binomial_probs, alpha=0.7, color='skyblue', edgecolor='navy')\n",
    "ax1.set_xlabel('Number of Successes (k)')\n",
    "ax1.set_ylabel('Probability P(X = k)')\n",
    "ax1.set_title('Binomial Distribution PMF\\n(n=10, p=0.5)')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# CDF Plot\n",
    "cdf_values = binom.cdf(k_values, n, p)\n",
    "ax2.step(k_values, cdf_values, where='post', linewidth=2, color='red')\n",
    "ax2.set_xlabel('Number of Successes (k)')\n",
    "ax2.set_ylabel('Cumulative Probability P(X ≤ k)')\n",
    "ax2.set_title('Binomial Distribution CDF\\n(n=10, p=0.5)')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Practical example\n",
    "print(\"\\n=== Practical Example ===\")\n",
    "print(\"What's the probability of getting exactly 5 heads in 10 coin flips?\")\n",
    "prob_5_heads = binom.pmf(5, n, p)\n",
    "print(f\"P(X = 5) = {prob_5_heads:.4f} = {prob_5_heads*100:.2f}%\")\n",
    "\n",
    "print(\"\\nWhat's the probability of getting at most 3 heads?\")\n",
    "prob_at_most_3 = binom.cdf(3, n, p)\n",
    "print(f\"P(X ≤ 3) = {prob_at_most_3:.4f} = {prob_at_most_3*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370caaf0",
   "metadata": {},
   "source": [
    "### Poisson Distribution\n",
    "\n",
    "The **Poisson Distribution** models the number of events occurring in a fixed interval of time or space.\n",
    "\n",
    "**Parameters**:\n",
    "- λ (lambda): average rate of occurrence\n",
    "\n",
    "**PMF**: P(X = k) = (λ^k × e^(-λ)) / k!\n",
    "\n",
    "**Example**: Number of emails received per hour\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec5885f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poisson Distribution Example\n",
    "print(\"=== Poisson Distribution ===\")\n",
    "print()\n",
    "\n",
    "# Parameters\n",
    "lambda_param = 3  # average rate (e.g., 3 emails per hour)\n",
    "\n",
    "# Generate Poisson distribution\n",
    "k_values = np.arange(0, 15)  # 0 to 14 events\n",
    "poisson_probs = poisson.pmf(k_values, lambda_param)\n",
    "\n",
    "print(f\"Parameter: λ = {lambda_param}\")\n",
    "print(f\"Mean: μ = λ = {lambda_param}\")\n",
    "print(f\"Variance: σ² = λ = {lambda_param}\")\n",
    "print(f\"Standard Deviation: σ = √λ = {np.sqrt(lambda_param):.2f}\")\n",
    "print()\n",
    "\n",
    "# Display probabilities\n",
    "print(\"Probability Mass Function:\")\n",
    "print(\"=\" * 40)\n",
    "for k, prob in zip(k_values[:8], poisson_probs[:8]):  # Show first 8\n",
    "    print(f\"P(X = {k:2d}) = {prob:.4f}\")\n",
    "print(\"...\")\n",
    "\n",
    "# Visualization\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# PMF Plot\n",
    "ax1.bar(k_values, poisson_probs, alpha=0.7, color='lightcoral', edgecolor='darkred')\n",
    "ax1.set_xlabel('Number of Events (k)')\n",
    "ax1.set_ylabel('Probability P(X = k)')\n",
    "ax1.set_title(f'Poisson Distribution PMF\\n(λ = {lambda_param})')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# CDF Plot\n",
    "cdf_values = poisson.cdf(k_values, lambda_param)\n",
    "ax2.step(k_values, cdf_values, where='post', linewidth=2, color='purple')\n",
    "ax2.set_xlabel('Number of Events (k)')\n",
    "ax2.set_ylabel('Cumulative Probability P(X ≤ k)')\n",
    "ax2.set_title(f'Poisson Distribution CDF\\n(λ = {lambda_param})')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Practical example\n",
    "print(\"\\n=== Practical Example ===\")\n",
    "print(\"What's the probability of receiving exactly 2 emails in an hour?\")\n",
    "prob_2_emails = poisson.pmf(2, lambda_param)\n",
    "print(f\"P(X = 2) = {prob_2_emails:.4f} = {prob_2_emails*100:.2f}%\")\n",
    "\n",
    "print(\"\\nWhat's the probability of receiving at most 1 email?\")\n",
    "prob_at_most_1 = poisson.cdf(1, lambda_param)\n",
    "print(f\"P(X ≤ 1) = {prob_at_most_1:.4f} = {prob_at_most_1*100:.2f}%\")\n",
    "\n",
    "print(\"\\nWhat's the probability of receiving more than 5 emails?\")\n",
    "prob_more_than_5 = 1 - poisson.cdf(5, lambda_param)\n",
    "print(f\"P(X > 5) = 1 - P(X ≤ 5) = 1 - {poisson.cdf(5, lambda_param):.4f} = {prob_more_than_5:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbe1154",
   "metadata": {},
   "source": [
    "## 5. Continuous Probability Distributions\n",
    "\n",
    "### Normal Distribution (Gaussian Distribution)\n",
    "\n",
    "The **Normal Distribution** is the most important continuous distribution, characterized by its bell-shaped curve.\n",
    "\n",
    "**Parameters**:\n",
    "- μ (mu): mean\n",
    "- σ (sigma): standard deviation\n",
    "\n",
    "**PDF**: f(x) = (1/σ√(2π)) × e^(-½((x-μ)/σ)²)\n",
    "\n",
    "**Properties**:\n",
    "- Symmetric about the mean\n",
    "- 68-95-99.7 rule: 68% within 1σ, 95% within 2σ, 99.7% within 3σ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461e7aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal Distribution Example\n",
    "print(\"=== Normal Distribution ===\")\n",
    "print()\n",
    "\n",
    "# Parameters\n",
    "mu = 0      # mean\n",
    "sigma = 1   # standard deviation\n",
    "\n",
    "# Generate normal distribution\n",
    "x = np.linspace(-4, 4, 1000)\n",
    "pdf_values = norm.pdf(x, mu, sigma)\n",
    "cdf_values = norm.cdf(x, mu, sigma)\n",
    "\n",
    "print(f\"Parameters: μ = {mu}, σ = {sigma}\")\n",
    "print(f\"Mean: μ = {mu}\")\n",
    "print(f\"Variance: σ² = {sigma**2}\")\n",
    "print(f\"Standard Deviation: σ = {sigma}\")\n",
    "print()\n",
    "\n",
    "# Visualization\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# PDF Plot\n",
    "ax1.plot(x, pdf_values, 'b-', linewidth=2, label='PDF')\n",
    "ax1.fill_between(x, pdf_values, alpha=0.3, color='blue')\n",
    "ax1.axvline(mu, color='red', linestyle='--', label=f'Mean (μ = {mu})')\n",
    "ax1.set_xlabel('x')\n",
    "ax1.set_ylabel('Probability Density f(x)')\n",
    "ax1.set_title(f'Normal Distribution PDF\\n(μ = {mu}, σ = {sigma})')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# CDF Plot\n",
    "ax2.plot(x, cdf_values, 'r-', linewidth=2, label='CDF')\n",
    "ax2.axvline(mu, color='red', linestyle='--', label=f'Mean (μ = {mu})')\n",
    "ax2.set_xlabel('x')\n",
    "ax2.set_ylabel('Cumulative Probability F(x)')\n",
    "ax2.set_title(f'Normal Distribution CDF\\n(μ = {mu}, σ = {sigma})')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 68-95-99.7 Rule demonstration\n",
    "print(\"=== 68-95-99.7 Rule ===\")\n",
    "print()\n",
    "\n",
    "# Calculate probabilities for different ranges\n",
    "prob_1_sigma = norm.cdf(mu + sigma, mu, sigma) - norm.cdf(mu - sigma, mu, sigma)\n",
    "prob_2_sigma = norm.cdf(mu + 2*sigma, mu, sigma) - norm.cdf(mu - 2*sigma, mu, sigma)\n",
    "prob_3_sigma = norm.cdf(mu + 3*sigma, mu, sigma) - norm.cdf(mu - 3*sigma, mu, sigma)\n",
    "\n",
    "print(f\"P(μ - σ ≤ X ≤ μ + σ) = P({mu-sigma:.1f} ≤ X ≤ {mu+sigma:.1f}) = {prob_1_sigma:.3f} ≈ 68%\")\n",
    "print(f\"P(μ - 2σ ≤ X ≤ μ + 2σ) = P({mu-2*sigma:.1f} ≤ X ≤ {mu+2*sigma:.1f}) = {prob_2_sigma:.3f} ≈ 95%\")\n",
    "print(f\"P(μ - 3σ ≤ X ≤ μ + 3σ) = P({mu-3*sigma:.1f} ≤ X ≤ {mu+3*sigma:.1f}) = {prob_3_sigma:.3f} ≈ 99.7%\")\n",
    "print()\n",
    "\n",
    "# Practical examples\n",
    "print(\"=== Practical Examples ===\")\n",
    "print(\"What's the probability that X ≤ 1?\")\n",
    "prob_less_than_1 = norm.cdf(1, mu, sigma)\n",
    "print(f\"P(X ≤ 1) = {prob_less_than_1:.4f} = {prob_less_than_1*100:.2f}%\")\n",
    "\n",
    "print(\"\\nWhat's the probability that X > 2?\")\n",
    "prob_greater_than_2 = 1 - norm.cdf(2, mu, sigma)\n",
    "print(f\"P(X > 2) = 1 - P(X ≤ 2) = 1 - {norm.cdf(2, mu, sigma):.4f} = {prob_greater_than_2:.4f}\")\n",
    "\n",
    "print(\"\\nWhat's the probability that -1 ≤ X ≤ 1?\")\n",
    "prob_between = norm.cdf(1, mu, sigma) - norm.cdf(-1, mu, sigma)\n",
    "print(f\"P(-1 ≤ X ≤ 1) = P(X ≤ 1) - P(X ≤ -1) = {norm.cdf(1, mu, sigma):.4f} - {norm.cdf(-1, mu, sigma):.4f} = {prob_between:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd240c3",
   "metadata": {},
   "source": [
    "### Uniform Distribution\n",
    "\n",
    "The **Uniform Distribution** has equal probability density over a specified interval.\n",
    "\n",
    "**Parameters**:\n",
    "- a: lower bound\n",
    "- b: upper bound\n",
    "\n",
    "**PDF**: f(x) = 1/(b-a) for a ≤ x ≤ b, 0 otherwise\n",
    "\n",
    "**Example**: Random number generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba9d2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uniform Distribution Example\n",
    "print(\"=== Uniform Distribution ===\")\n",
    "print()\n",
    "\n",
    "# Parameters\n",
    "a = 0  # lower bound\n",
    "b = 10  # upper bound\n",
    "\n",
    "# Generate uniform distribution\n",
    "x = np.linspace(-2, 12, 1000)\n",
    "pdf_values = uniform.pdf(x, a, b-a)\n",
    "cdf_values = uniform.cdf(x, a, b-a)\n",
    "\n",
    "print(f\"Parameters: a = {a}, b = {b}\")\n",
    "print(f\"Mean: μ = (a + b)/2 = ({a} + {b})/2 = {(a+b)/2}\")\n",
    "print(f\"Variance: σ² = (b-a)²/12 = ({b}-{a})²/12 = {((b-a)**2)/12:.2f}\")\n",
    "print(f\"Standard Deviation: σ = (b-a)/√12 = {((b-a)/np.sqrt(12)):.2f}\")\n",
    "print()\n",
    "\n",
    "# Visualization\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# PDF Plot\n",
    "ax1.plot(x, pdf_values, 'g-', linewidth=2, label='PDF')\n",
    "ax1.fill_between(x, pdf_values, alpha=0.3, color='green')\n",
    "ax1.axvline(a, color='red', linestyle='--', label=f'Lower bound (a = {a})')\n",
    "ax1.axvline(b, color='red', linestyle='--', label=f'Upper bound (b = {b})')\n",
    "ax1.set_xlabel('x')\n",
    "ax1.set_ylabel('Probability Density f(x)')\n",
    "ax1.set_title(f'Uniform Distribution PDF\\n(a = {a}, b = {b})')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# CDF Plot\n",
    "ax2.plot(x, cdf_values, 'orange', linewidth=2, label='CDF')\n",
    "ax2.axvline(a, color='red', linestyle='--', label=f'Lower bound (a = {a})')\n",
    "ax2.axvline(b, color='red', linestyle='--', label=f'Upper bound (b = {b})')\n",
    "ax2.set_xlabel('x')\n",
    "ax2.set_ylabel('Cumulative Probability F(x)')\n",
    "ax2.set_title(f'Uniform Distribution CDF\\n(a = {a}, b = {b})')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Practical examples\n",
    "print(\"=== Practical Examples ===\")\n",
    "print(\"What's the probability that X ≤ 3?\")\n",
    "prob_less_than_3 = uniform.cdf(3, a, b-a)\n",
    "print(f\"P(X ≤ 3) = {prob_less_than_3:.4f} = {prob_less_than_3*100:.2f}%\")\n",
    "\n",
    "print(\"\\nWhat's the probability that 2 ≤ X ≤ 8?\")\n",
    "prob_between = uniform.cdf(8, a, b-a) - uniform.cdf(2, a, b-a)\n",
    "print(f\"P(2 ≤ X ≤ 8) = P(X ≤ 8) - P(X ≤ 2) = {uniform.cdf(8, a, b-a):.4f} - {uniform.cdf(2, a, b-a):.4f} = {prob_between:.4f}\")\n",
    "\n",
    "print(\"\\nWhat's the probability density at x = 5?\")\n",
    "pdf_at_5 = uniform.pdf(5, a, b-a)\n",
    "print(f\"f(5) = {pdf_at_5:.4f}\")\n",
    "\n",
    "# Compare different distributions\n",
    "print(\"\\n=== Distribution Comparison ===\")\n",
    "print(\"Let's compare Normal, Uniform, and Exponential distributions:\")\n",
    "print()\n",
    "\n",
    "# Generate data for comparison\n",
    "x_norm = np.linspace(-3, 8, 1000)\n",
    "x_unif = np.linspace(-1, 11, 1000)\n",
    "x_exp = np.linspace(0, 8, 1000)\n",
    "\n",
    "pdf_norm = norm.pdf(x_norm, 2, 1)\n",
    "pdf_unif = uniform.pdf(x_unif, 0, 10)\n",
    "pdf_exp = expon.pdf(x_exp, 0, 2)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(x_norm, pdf_norm, 'b-', linewidth=2, label='Normal (μ=2, σ=1)')\n",
    "plt.plot(x_unif, pdf_unif, 'g-', linewidth=2, label='Uniform (a=0, b=10)')\n",
    "plt.plot(x_exp, pdf_exp, 'r-', linewidth=2, label='Exponential (λ=0.5)')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.title('Comparison of Probability Distributions')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493d5e20",
   "metadata": {},
   "source": [
    "## 6. Bayesian Probability\n",
    "\n",
    "### What is Bayesian Probability?\n",
    "\n",
    "**Bayesian Probability** is a framework for updating our beliefs about the probability of an event as we gather more evidence. It's based on Bayes' Theorem, which provides a way to revise prior probabilities with new information.\n",
    "\n",
    "### Bayes' Theorem\n",
    "\n",
    "**Formula**: P(A|B) = P(B|A) × P(A) / P(B)\n",
    "\n",
    "Where:\n",
    "- **P(A|B)**: Posterior probability (updated belief)\n",
    "- **P(B|A)**: Likelihood (probability of evidence given hypothesis)\n",
    "- **P(A)**: Prior probability (initial belief)\n",
    "- **P(B)**: Marginal likelihood (probability of evidence)\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "1. **Prior**: Our initial belief about the probability of an event\n",
    "2. **Likelihood**: How likely the observed evidence is given our hypothesis\n",
    "3. **Posterior**: Our updated belief after considering the evidence\n",
    "4. **Evidence**: New information that helps us update our beliefs\n",
    "\n",
    "### Applications in Machine Learning\n",
    "\n",
    "- **Naive Bayes Classifier**: Email spam detection, text classification\n",
    "- **Bayesian Networks**: Probabilistic graphical models\n",
    "- **Bayesian Optimization**: Hyperparameter tuning\n",
    "- **Bayesian Neural Networks**: Uncertainty quantification\n",
    "\n",
    "Let's explore Bayesian probability with practical examples!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a189034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Medical Diagnosis (Classic Bayesian Example)\n",
    "print(\"=== Example 1: Medical Diagnosis ===\")\n",
    "print()\n",
    "\n",
    "# Given information\n",
    "P_disease = 0.01  # Prior: 1% of population has the disease\n",
    "P_positive_given_disease = 0.95  # Likelihood: 95% test accuracy if you have disease\n",
    "P_positive_given_no_disease = 0.05  # False positive rate: 5%\n",
    "\n",
    "print(\"Given Information:\")\n",
    "print(f\"P(Disease) = {P_disease:.2f} (Prior)\")\n",
    "print(f\"P(Positive Test | Disease) = {P_positive_given_disease:.2f} (Sensitivity)\")\n",
    "print(f\"P(Positive Test | No Disease) = {P_positive_given_no_disease:.2f} (False Positive Rate)\")\n",
    "print()\n",
    "\n",
    "# Calculate marginal probability P(Positive Test)\n",
    "P_positive = P_positive_given_disease * P_disease + P_positive_given_no_disease * (1 - P_disease)\n",
    "print(f\"P(Positive Test) = P(Positive|Disease)×P(Disease) + P(Positive|No Disease)×P(No Disease)\")\n",
    "print(f\"P(Positive Test) = {P_positive_given_disease:.2f}×{P_disease:.2f} + {P_positive_given_no_disease:.2f}×{1-P_disease:.2f}\")\n",
    "print(f\"P(Positive Test) = {P_positive_given_disease * P_disease:.3f} + {P_positive_given_no_disease * (1 - P_disease):.3f} = {P_positive:.3f}\")\n",
    "print()\n",
    "\n",
    "# Apply Bayes' Theorem\n",
    "P_disease_given_positive = (P_positive_given_disease * P_disease) / P_positive\n",
    "print(\"Applying Bayes' Theorem:\")\n",
    "print(f\"P(Disease | Positive Test) = P(Positive|Disease) × P(Disease) / P(Positive Test)\")\n",
    "print(f\"P(Disease | Positive Test) = {P_positive_given_disease:.2f} × {P_disease:.2f} / {P_positive:.3f}\")\n",
    "print(f\"P(Disease | Positive Test) = {P_disease_given_positive:.3f} = {P_disease_given_positive*100:.1f}%\")\n",
    "print()\n",
    "\n",
    "print(\"Interpretation:\")\n",
    "print(f\"Even with a positive test result, there's only a {P_disease_given_positive*100:.1f}% chance of having the disease!\")\n",
    "print(\"This is because the disease is rare (1% prevalence) and the false positive rate is significant.\")\n",
    "print()\n",
    "\n",
    "# Example 2: Email Spam Detection\n",
    "print(\"=== Example 2: Email Spam Detection ===\")\n",
    "print()\n",
    "\n",
    "# Given information for spam detection\n",
    "P_spam = 0.3  # Prior: 30% of emails are spam\n",
    "P_word_given_spam = 0.8  # Likelihood: 80% of spam emails contain word \"free\"\n",
    "P_word_given_not_spam = 0.1  # Likelihood: 10% of legitimate emails contain word \"free\"\n",
    "\n",
    "print(\"Given Information:\")\n",
    "print(f\"P(Spam) = {P_spam:.2f} (Prior)\")\n",
    "print(f\"P('free' | Spam) = {P_word_given_spam:.2f}\")\n",
    "print(f\"P('free' | Not Spam) = {P_word_given_not_spam:.2f}\")\n",
    "print()\n",
    "\n",
    "# Calculate marginal probability P('free')\n",
    "P_word = P_word_given_spam * P_spam + P_word_given_not_spam * (1 - P_spam)\n",
    "print(f\"P('free') = P('free'|Spam)×P(Spam) + P('free'|Not Spam)×P(Not Spam)\")\n",
    "print(f\"P('free') = {P_word_given_spam:.2f}×{P_spam:.2f} + {P_word_given_not_spam:.2f}×{1-P_spam:.2f}\")\n",
    "print(f\"P('free') = {P_word_given_spam * P_spam:.2f} + {P_word_given_not_spam * (1 - P_spam):.2f} = {P_word:.2f}\")\n",
    "print()\n",
    "\n",
    "# Apply Bayes' Theorem\n",
    "P_spam_given_word = (P_word_given_spam * P_spam) / P_word\n",
    "print(\"Applying Bayes' Theorem:\")\n",
    "print(f\"P(Spam | 'free') = P('free'|Spam) × P(Spam) / P('free')\")\n",
    "print(f\"P(Spam | 'free') = {P_word_given_spam:.2f} × {P_spam:.2f} / {P_word:.2f}\")\n",
    "print(f\"P(Spam | 'free') = {P_spam_given_word:.3f} = {P_spam_given_word*100:.1f}%\")\n",
    "print()\n",
    "\n",
    "print(\"Interpretation:\")\n",
    "print(f\"An email containing the word 'free' has a {P_spam_given_word*100:.1f}% probability of being spam.\")\n",
    "print(\"This is much higher than the prior probability of 30%!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad2fff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive Bayesian Update Visualization\n",
    "print(\"=== Interactive Bayesian Update ===\")\n",
    "print()\n",
    "\n",
    "def bayesian_update(prior, likelihood_pos, likelihood_neg, evidence):\n",
    "    \"\"\"\n",
    "    Perform Bayesian update given prior, likelihoods, and evidence\n",
    "    \"\"\"\n",
    "    if evidence == 1:  # Positive evidence\n",
    "        posterior = (likelihood_pos * prior) / (likelihood_pos * prior + likelihood_neg * (1 - prior))\n",
    "    else:  # Negative evidence\n",
    "        posterior = ((1 - likelihood_pos) * prior) / ((1 - likelihood_pos) * prior + (1 - likelihood_neg) * (1 - prior))\n",
    "    \n",
    "    return posterior\n",
    "\n",
    "# Example: Multiple pieces of evidence\n",
    "print(\"Example: Multiple Evidence Updates\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Initial prior\n",
    "prior = 0.1  # 10% chance of rain\n",
    "print(f\"Initial Prior: P(Rain) = {prior:.2f}\")\n",
    "\n",
    "# Evidence 1: Dark clouds\n",
    "likelihood_pos_1 = 0.8  # P(Dark clouds | Rain)\n",
    "likelihood_neg_1 = 0.2  # P(Dark clouds | No rain)\n",
    "\n",
    "posterior_1 = bayesian_update(prior, likelihood_pos_1, likelihood_neg_1, 1)\n",
    "print(f\"After seeing dark clouds: P(Rain | Dark clouds) = {posterior_1:.3f}\")\n",
    "\n",
    "# Evidence 2: Barometer dropping\n",
    "likelihood_pos_2 = 0.9  # P(Barometer drops | Rain)\n",
    "likelihood_neg_2 = 0.1  # P(Barometer drops | No rain)\n",
    "\n",
    "posterior_2 = bayesian_update(posterior_1, likelihood_pos_2, likelihood_neg_2, 1)\n",
    "print(f\"After barometer drops: P(Rain | Both evidences) = {posterior_2:.3f}\")\n",
    "\n",
    "# Evidence 3: Weather forecast says no rain\n",
    "likelihood_pos_3 = 0.1  # P(Forecast says no rain | Rain)\n",
    "likelihood_neg_3 = 0.9  # P(Forecast says no rain | No rain)\n",
    "\n",
    "posterior_3 = bayesian_update(posterior_2, likelihood_pos_3, likelihood_neg_3, 0)\n",
    "print(f\"After forecast says no rain: P(Rain | All evidences) = {posterior_3:.3f}\")\n",
    "\n",
    "print()\n",
    "print(\"Interpretation:\")\n",
    "print(f\"• Started with {prior*100:.0f}% chance of rain\")\n",
    "print(f\"• Dark clouds increased it to {posterior_1*100:.1f}%\")\n",
    "print(f\"• Barometer drop increased it to {posterior_2*100:.1f}%\")\n",
    "print(f\"• Weather forecast decreased it to {posterior_3*100:.1f}%\")\n",
    "print()\n",
    "\n",
    "# Visualization of Bayesian update process\n",
    "steps = ['Prior', 'Dark Clouds', 'Barometer Drop', 'Forecast Says No Rain']\n",
    "probabilities = [prior, posterior_1, posterior_2, posterior_3]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(steps, probabilities, 'bo-', linewidth=2, markersize=8)\n",
    "plt.fill_between(range(len(steps)), probabilities, alpha=0.3, color='blue')\n",
    "plt.xlabel('Evidence Step')\n",
    "plt.ylabel('Probability of Rain')\n",
    "plt.title('Bayesian Update Process: Probability of Rain')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "# Add probability values on the plot\n",
    "for i, (step, prob) in enumerate(zip(steps, probabilities)):\n",
    "    plt.annotate(f'{prob:.3f}', (i, prob), textcoords=\"offset points\", xytext=(0,10), ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Naive Bayes Classifier Example\n",
    "print(\"=== Naive Bayes Classifier Example ===\")\n",
    "print()\n",
    "\n",
    "# Simple text classification example\n",
    "def naive_bayes_classifier():\n",
    "    \"\"\"\n",
    "    Simple Naive Bayes classifier for text classification\n",
    "    \"\"\"\n",
    "    # Training data\n",
    "    spam_words = ['free', 'money', 'win', 'urgent', 'click']\n",
    "    ham_words = ['meeting', 'project', 'team', 'work', 'schedule']\n",
    "    \n",
    "    # Prior probabilities\n",
    "    P_spam = 0.3\n",
    "    P_ham = 0.7\n",
    "    \n",
    "    # Word frequencies in spam and ham\n",
    "    spam_word_freq = {'free': 0.8, 'money': 0.6, 'win': 0.4, 'urgent': 0.3, 'click': 0.5}\n",
    "    ham_word_freq = {'meeting': 0.4, 'project': 0.5, 'team': 0.3, 'work': 0.6, 'schedule': 0.2}\n",
    "    \n",
    "    # Test email\n",
    "    test_email = ['free', 'money', 'meeting']\n",
    "    \n",
    "    print(f\"Test email words: {test_email}\")\n",
    "    print()\n",
    "    \n",
    "    # Calculate likelihood for spam\n",
    "    spam_likelihood = 1.0\n",
    "    for word in test_email:\n",
    "        if word in spam_word_freq:\n",
    "            spam_likelihood *= spam_word_freq[word]\n",
    "        else:\n",
    "            spam_likelihood *= 0.1  # Small probability for unknown words\n",
    "    \n",
    "    # Calculate likelihood for ham\n",
    "    ham_likelihood = 1.0\n",
    "    for word in test_email:\n",
    "        if word in ham_word_freq:\n",
    "            ham_likelihood *= ham_word_freq[word]\n",
    "        else:\n",
    "            ham_likelihood *= 0.1  # Small probability for unknown words\n",
    "    \n",
    "    # Calculate posterior probabilities\n",
    "    spam_posterior = (spam_likelihood * P_spam) / (spam_likelihood * P_spam + ham_likelihood * P_ham)\n",
    "    ham_posterior = (ham_likelihood * P_ham) / (spam_likelihood * P_spam + ham_likelihood * P_ham)\n",
    "    \n",
    "    print(f\"Spam likelihood: {spam_likelihood:.4f}\")\n",
    "    print(f\"Ham likelihood: {ham_likelihood:.4f}\")\n",
    "    print()\n",
    "    print(f\"P(Spam | email) = {spam_posterior:.4f} = {spam_posterior*100:.1f}%\")\n",
    "    print(f\"P(Ham | email) = {ham_posterior:.4f} = {ham_posterior*100:.1f}%\")\n",
    "    print()\n",
    "    \n",
    "    if spam_posterior > ham_posterior:\n",
    "        print(\"Classification: SPAM\")\n",
    "    else:\n",
    "        print(\"Classification: HAM\")\n",
    "\n",
    "naive_bayes_classifier()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f81687d",
   "metadata": {},
   "source": [
    "## 7. Hands-on Exercises and Practice Problems\n",
    "\n",
    "### Exercise 1: Basic Probability Calculations\n",
    "\n",
    "**Problem**: A bag contains 5 red balls, 3 blue balls, and 2 green balls. If you randomly select one ball:\n",
    "\n",
    "1. What is the probability of selecting a red ball?\n",
    "2. What is the probability of selecting a blue or green ball?\n",
    "3. What is the probability of not selecting a red ball?\n",
    "\n",
    "**Solution**:\n",
    "- Total balls = 5 + 3 + 2 = 10\n",
    "- P(Red) = 5/10 = 0.5\n",
    "- P(Blue or Green) = P(Blue) + P(Green) = 3/10 + 2/10 = 0.5\n",
    "- P(Not Red) = 1 - P(Red) = 1 - 0.5 = 0.5\n",
    "\n",
    "### Exercise 2: Conditional Probability\n",
    "\n",
    "**Problem**: In a class of 30 students, 18 are girls and 12 are boys. 8 girls and 6 boys wear glasses. If a student is selected at random:\n",
    "\n",
    "1. What is the probability that the student wears glasses?\n",
    "2. What is the probability that a girl wears glasses?\n",
    "3. What is the probability that a student wearing glasses is a girl?\n",
    "\n",
    "### Exercise 3: Binomial Distribution\n",
    "\n",
    "**Problem**: A fair coin is flipped 8 times. Calculate:\n",
    "\n",
    "1. The probability of getting exactly 4 heads\n",
    "2. The probability of getting at most 2 heads\n",
    "3. The probability of getting at least 6 heads\n",
    "\n",
    "### Exercise 4: Normal Distribution\n",
    "\n",
    "**Problem**: The heights of students in a class follow a normal distribution with mean 170 cm and standard deviation 10 cm. Calculate:\n",
    "\n",
    "1. The probability that a randomly selected student is taller than 180 cm\n",
    "2. The probability that a student's height is between 160 cm and 180 cm\n",
    "3. The height below which 25% of students fall\n",
    "\n",
    "### Exercise 5: Bayesian Probability\n",
    "\n",
    "**Problem**: A factory produces widgets. 5% of widgets are defective. A quality control test correctly identifies 90% of defective widgets and 95% of non-defective widgets. If a widget tests positive:\n",
    "\n",
    "1. What is the probability that it is actually defective?\n",
    "2. What is the probability that it is not defective despite testing positive?\n",
    "\n",
    "Let's solve these exercises step by step!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8247c030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise Solutions\n",
    "print(\"=== EXERCISE SOLUTIONS ===\")\n",
    "print()\n",
    "\n",
    "# Exercise 1: Basic Probability Calculations\n",
    "print(\"Exercise 1: Basic Probability Calculations\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Given data\n",
    "red_balls = 5\n",
    "blue_balls = 3\n",
    "green_balls = 2\n",
    "total_balls = red_balls + blue_balls + green_balls\n",
    "\n",
    "print(f\"Given: {red_balls} red, {blue_balls} blue, {green_balls} green balls\")\n",
    "print(f\"Total balls: {total_balls}\")\n",
    "print()\n",
    "\n",
    "# Calculations\n",
    "P_red = red_balls / total_balls\n",
    "P_blue = blue_balls / total_balls\n",
    "P_green = green_balls / total_balls\n",
    "P_blue_or_green = P_blue + P_green\n",
    "P_not_red = 1 - P_red\n",
    "\n",
    "print(\"Solutions:\")\n",
    "print(f\"1. P(Red) = {red_balls}/{total_balls} = {P_red:.2f}\")\n",
    "print(f\"2. P(Blue or Green) = P(Blue) + P(Green) = {blue_balls}/{total_balls} + {green_balls}/{total_balls} = {P_blue_or_green:.2f}\")\n",
    "print(f\"3. P(Not Red) = 1 - P(Red) = 1 - {P_red:.2f} = {P_not_red:.2f}\")\n",
    "print()\n",
    "\n",
    "# Exercise 2: Conditional Probability\n",
    "print(\"Exercise 2: Conditional Probability\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Given data\n",
    "total_students = 30\n",
    "girls = 18\n",
    "boys = 12\n",
    "girls_with_glasses = 8\n",
    "boys_with_glasses = 6\n",
    "total_with_glasses = girls_with_glasses + boys_with_glasses\n",
    "\n",
    "print(f\"Given: {total_students} students ({girls} girls, {boys} boys)\")\n",
    "print(f\"Girls with glasses: {girls_with_glasses}, Boys with glasses: {boys_with_glasses}\")\n",
    "print()\n",
    "\n",
    "# Calculations\n",
    "P_glasses = total_with_glasses / total_students\n",
    "P_glasses_given_girl = girls_with_glasses / girls\n",
    "P_girl_given_glasses = girls_with_glasses / total_with_glasses\n",
    "\n",
    "print(\"Solutions:\")\n",
    "print(f\"1. P(Glasses) = {total_with_glasses}/{total_students} = {P_glasses:.3f}\")\n",
    "print(f\"2. P(Glasses | Girl) = {girls_with_glasses}/{girls} = {P_glasses_given_girl:.3f}\")\n",
    "print(f\"3. P(Girl | Glasses) = {girls_with_glasses}/{total_with_glasses} = {P_girl_given_glasses:.3f}\")\n",
    "print()\n",
    "\n",
    "# Exercise 3: Binomial Distribution\n",
    "print(\"Exercise 3: Binomial Distribution\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Parameters\n",
    "n = 8  # number of trials\n",
    "p = 0.5  # probability of success (heads)\n",
    "\n",
    "print(f\"Given: Fair coin flipped {n} times\")\n",
    "print()\n",
    "\n",
    "# Calculations\n",
    "prob_exactly_4 = binom.pmf(4, n, p)\n",
    "prob_at_most_2 = binom.cdf(2, n, p)\n",
    "prob_at_least_6 = 1 - binom.cdf(5, n, p)\n",
    "\n",
    "print(\"Solutions:\")\n",
    "print(f\"1. P(Exactly 4 heads) = {prob_exactly_4:.4f}\")\n",
    "print(f\"2. P(At most 2 heads) = P(X ≤ 2) = {prob_at_most_2:.4f}\")\n",
    "print(f\"3. P(At least 6 heads) = P(X ≥ 6) = 1 - P(X ≤ 5) = {prob_at_least_6:.4f}\")\n",
    "print()\n",
    "\n",
    "# Exercise 4: Normal Distribution\n",
    "print(\"Exercise 4: Normal Distribution\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Parameters\n",
    "mu = 170  # mean height\n",
    "sigma = 10  # standard deviation\n",
    "\n",
    "print(f\"Given: Heights ~ Normal(μ = {mu} cm, σ = {sigma} cm)\")\n",
    "print()\n",
    "\n",
    "# Calculations\n",
    "prob_taller_than_180 = 1 - norm.cdf(180, mu, sigma)\n",
    "prob_between_160_180 = norm.cdf(180, mu, sigma) - norm.cdf(160, mu, sigma)\n",
    "height_25th_percentile = norm.ppf(0.25, mu, sigma)\n",
    "\n",
    "print(\"Solutions:\")\n",
    "print(f\"1. P(Height > 180 cm) = 1 - P(Height ≤ 180) = {prob_taller_than_180:.4f}\")\n",
    "print(f\"2. P(160 ≤ Height ≤ 180) = P(Height ≤ 180) - P(Height ≤ 160) = {prob_between_160_180:.4f}\")\n",
    "print(f\"3. Height below which 25% fall = {height_25th_percentile:.1f} cm\")\n",
    "print()\n",
    "\n",
    "# Exercise 5: Bayesian Probability\n",
    "print(\"Exercise 5: Bayesian Probability\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Given data\n",
    "P_defective = 0.05  # Prior: 5% defective\n",
    "P_positive_given_defective = 0.90  # Test correctly identifies 90% of defective\n",
    "P_positive_given_not_defective = 0.05  # Test incorrectly identifies 5% of non-defective\n",
    "\n",
    "print(f\"Given: {P_defective*100:.0f}% widgets defective\")\n",
    "print(f\"Test accuracy: {P_positive_given_defective*100:.0f}% for defective, {P_positive_given_not_defective*100:.0f}% false positive\")\n",
    "print()\n",
    "\n",
    "# Calculations\n",
    "P_positive = P_positive_given_defective * P_defective + P_positive_given_not_defective * (1 - P_defective)\n",
    "P_defective_given_positive = (P_positive_given_defective * P_defective) / P_positive\n",
    "P_not_defective_given_positive = 1 - P_defective_given_positive\n",
    "\n",
    "print(\"Solutions:\")\n",
    "print(f\"1. P(Defective | Positive Test) = {P_defective_given_positive:.4f} = {P_defective_given_positive*100:.1f}%\")\n",
    "print(f\"2. P(Not Defective | Positive Test) = {P_not_defective_given_positive:.4f} = {P_not_defective_given_positive*100:.1f}%\")\n",
    "print()\n",
    "\n",
    "print(\"Interpretation:\")\n",
    "print(f\"Even with a positive test, there's only a {P_defective_given_positive*100:.1f}% chance the widget is actually defective!\")\n",
    "print(\"This is because the defect rate is low (5%) and the false positive rate is significant.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73a2584",
   "metadata": {},
   "source": [
    "## 8. Summary and Key Takeaways\n",
    "\n",
    "### What We've Learned\n",
    "\n",
    "In this comprehensive hands-on lecture on probability, we've covered:\n",
    "\n",
    "#### 1. **Probability Fundamentals**\n",
    "- Probability measures likelihood (0 to 1)\n",
    "- Sample space, events, and probability axioms\n",
    "- Basic probability calculations with practical examples\n",
    "\n",
    "#### 2. **Joint, Marginal, and Conditional Probability**\n",
    "- **Joint Probability**: P(A ∩ B) - both events occur\n",
    "- **Marginal Probability**: P(A) - single event probability\n",
    "- **Conditional Probability**: P(A|B) - probability given another event\n",
    "- Independence and dependence relationships\n",
    "\n",
    "#### 3. **Probability Distributions**\n",
    "- Mathematical models for random phenomena\n",
    "- PMF for discrete variables, PDF for continuous variables\n",
    "- CDF for cumulative probabilities\n",
    "\n",
    "#### 4. **Discrete Distributions**\n",
    "- **Binomial**: Number of successes in n trials\n",
    "- **Poisson**: Number of events in fixed intervals\n",
    "- Parameters, formulas, and practical applications\n",
    "\n",
    "#### 5. **Continuous Distributions**\n",
    "- **Normal**: Bell-shaped curve, most common in nature\n",
    "- **Uniform**: Equal probability over intervals\n",
    "- 68-95-99.7 rule for normal distributions\n",
    "\n",
    "#### 6. **Bayesian Probability**\n",
    "- Updating beliefs with evidence using Bayes' Theorem\n",
    "- Prior → Likelihood → Posterior\n",
    "- Applications in machine learning and decision making\n",
    "\n",
    "### Key Formulas to Remember\n",
    "\n",
    "1. **Basic Probability**: P(A) = Favorable outcomes / Total outcomes\n",
    "2. **Conditional Probability**: P(A|B) = P(A ∩ B) / P(B)\n",
    "3. **Bayes' Theorem**: P(A|B) = P(B|A) × P(A) / P(B)\n",
    "4. **Independence**: P(A ∩ B) = P(A) × P(B)\n",
    "5. **Binomial PMF**: P(X = k) = C(n,k) × p^k × (1-p)^(n-k)\n",
    "6. **Poisson PMF**: P(X = k) = (λ^k × e^(-λ)) / k!\n",
    "\n",
    "### Applications in Machine Learning\n",
    "\n",
    "- **Classification**: Naive Bayes classifiers\n",
    "- **Regression**: Bayesian linear regression\n",
    "- **Optimization**: Bayesian optimization\n",
    "- **Uncertainty**: Bayesian neural networks\n",
    "- **Decision Making**: Risk assessment and decision theory\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Practice**: Work through more probability problems\n",
    "2. **Explore**: Learn about other distributions (exponential, gamma, beta)\n",
    "3. **Apply**: Use probability in your machine learning projects\n",
    "4. **Advanced**: Study Bayesian statistics and probabilistic programming\n",
    "\n",
    "### Resources for Further Learning\n",
    "\n",
    "- **Books**: \"Introduction to Probability\" by Joseph K. Blitzstein\n",
    "- **Online**: Khan Academy Probability course\n",
    "- **Tools**: Python scipy.stats, R probability packages\n",
    "- **Applications**: Bayesian inference, Monte Carlo methods\n",
    "\n",
    "---\n",
    "\n",
    "**Congratulations!** You've completed a comprehensive journey through probability theory. These concepts form the foundation for understanding machine learning algorithms, statistical inference, and data science. Keep practicing and applying these concepts in your projects!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8803f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ul-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
